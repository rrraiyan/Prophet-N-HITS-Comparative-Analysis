{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2514e5c",
      "metadata": {},
      "source": [
        "# Executive Summary\n",
        "\n",
        "## Project Objective\n",
        "This analysis benchmarks the efficacy of statistical modeling (Prophet) versus modern deep learning (NNN) for forecasting financial time series, using Adobe Inc. (ADBE) stock data as the dataset. The project prioritizes rigorous evaluation, employing a **walk-forward validation** framework that simulates real-world trading conditions to strictly prevent data leakage and ensure result integrity.\n",
        "\n",
        "## Methodology: A Dual-Model Approach\n",
        "Two distinct algorithmic paradigms were implemented and optimized via hyperparameter tuning (Optuna):\n",
        "\n",
        "* **Prophet (Statistical Decomposability):** Developed by Meta, this model operates on an additive principle, treating prediction as the sum of interpretable components rather than a \"black box.\" It mathematically constructs a forecast by combining a long-term **trend**, repeating **seasonal cycles** (weekly/yearly patterns), and known **holiday effects**. This model also takes into consideration **noise**, the patternless behaviors the algorithm can't explain. In this implementation, the model is further enhanced with **external regressors** (such as volatility and moving averages), allowing it to dynamically adjust its trajectory based on recent market momentum.\n",
        "\n",
        "* **N-HiTS (Hierarchical Deep Learning):** The Neural Hierarchical Interpolation for Time Series (N-HiTS) is a state-of-the-art deep learning architecture designed for stability and interpretability. Unlike traditional recurrent networks that process data sequentially, N-HiTS analyzes the entire history simultaneously through a \"multi-scale\" approach. It utilizes a stack of blocks where initial layers capture broad, low-frequency signals (long-term trends), while subsequent layers progressively zoom in to capture high-frequency details (short-term fluctuations). This \"coarse-to-fine\" synthesis allows the model to effectively separate genuine market signals from daily noise.\n",
        "\n",
        "## Validation Framework\n",
        "To accurately measure performance against standard **Persistence Baselines** (naive forecasts), the notebook utilizes a **leakage-proof rolling window** strategy. This ensures that all feature engineering, including scaling and lag generation, occurs dynamically at each time step, reflecting the exact information constraints of a live production algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fce040f",
      "metadata": {},
      "source": [
        "# Environment Setup & Data Acquisition\n",
        "\n",
        "## Library Initialization\n",
        "The analysis begins by establishing the computational environment. The technical stack is initialized here, incorporating:\n",
        "* **Data Manipulation:** `numpy` and `pandas` for array processing and dataframe management.\n",
        "* **Visualization:** `matplotlib` and `seaborn` for plotting.\n",
        "* **Forecasting Frameworks:** `prophet` for statistical additive modeling and `darts` (specifically `NHiTSModel`) for hierarchical deep learning.\n",
        "* **Optimization:** `optuna` for automated hyperparameter tuning.\n",
        "\n",
        "## Data Ingestion\n",
        "The dataset is retrieved programmatically using the `kagglehub` API to ensure reproducibility. The \"Stock Market Data\" repository is downloaded, and the specific data file for **Adobe Inc. (ADBE)** is located and loaded into memory. Initial inspection commands (`head`, `info`) are executed to verify the successful ingestion of the raw NASDAQ data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "108bec9c",
      "metadata": {
        "id": "108bec9c",
        "outputId": "23328c48-d768-411d-c6ba-0f17a3f48978"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import numpy as np #for powerful array and fast math operations\n",
        "import pandas as pd #for creating and working on dataframes\n",
        "import matplotlib.pyplot as plt #for creating plots and charts\n",
        "import seaborn as sns #another visualization library for better and easier plots\n",
        "import kagglehub #for interacting with kaggle to download datasets\n",
        "import os #for interacting with the os to read csv\n",
        "from prophet import Prophet #importing the prophet library\n",
        "from prophet.make_holidays import make_holidays_df #importing holidays for the algorithm\n",
        "from prophet.diagnostics import cross_validation, performance_metrics #importing cross validation and performance metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score #importing metrics to evaluate the models\n",
        "from prophet.plot import plot_cross_validation_metric #for plotting cross validation metrics\n",
        "import logging #for suppressing warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9747bd",
      "metadata": {
        "id": "ac9747bd",
        "outputId": "27d4e3e4-0ffa-46dd-f051-8620105de3b0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "import os\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Darts imports\n",
        "from darts import TimeSeries\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.models import NHiTSModel\n",
        "from darts.metrics import rmse\n",
        "\n",
        "# Optuna for hyperparameter tuning\n",
        "import optuna\n",
        "\n",
        "# PyTorch (required by Darts)\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707587a1",
      "metadata": {
        "id": "707587a1",
        "outputId": "03976a7b-6efa-4194-dbba-fc876045602e"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/stock-market-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7e9d58a",
      "metadata": {
        "id": "c7e9d58a",
        "outputId": "83a9853f-1e9c-4d87-ae91-3ad45a1baf6a"
      },
      "outputs": [],
      "source": [
        "# `path` points to the downloaded dataset directory\n",
        "dataset_dir = path\n",
        "\n",
        "# List files in the dataset directory to identify the data files\n",
        "print(\"Files in dataset directory:\", os.listdir(dataset_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cd7123",
      "metadata": {
        "id": "62cd7123",
        "outputId": "d6de5829-0227-4ca2-f5d5-04ad39c6a963"
      },
      "outputs": [],
      "source": [
        "# Load Adobe stock data\n",
        "adbe_path = os.path.join(dataset_dir, \"stock_market_data\", \"nasdaq\", \"csv\", \"ADBE.csv\")\n",
        "adbe_df = pd.read_csv(adbe_path)\n",
        "\n",
        "# Inspect first rows\n",
        "print(adbe_df.head())\n",
        "print(adbe_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19917fa",
      "metadata": {},
      "source": [
        "# Data Preprocessing & Exploratory Analysis\n",
        "\n",
        "## Data Integrity & Temporal Structure\n",
        "Before modeling, the dataset undergoes a rigorous quality assurance process. Timestamps are standardized to datetime objects, and a series of logical assertions verify data health, ensuring no missing values exist, all price points are positive, and no duplicate dates occur.\n",
        "\n",
        "A distinct feature of financial time series is the non-continuous nature of trading days. The analysis explicitly quantifies the timeline structure by calculating:\n",
        "* **Total Calendar Duration:** The absolute span from start to finish.\n",
        "* **Non-Trading Days:** Weekends and US public holidays (generated via `make_holidays_df`).\n",
        "* **Data Gaps:** By subtracting trading days and known closures from the total timeline, the workflow identifies any irregular gaps in the data record, ensuring the dataset represents a complete trading history.\n",
        "The data gap is -45 over 38 years, due to holiday dates mismatch with the Holiday library and stock market, which is negligible.\n",
        "\n",
        "## Visual Inspection\n",
        "Exploratory visualization provides an initial assessment of the asset's behavior. A long-term time series plot (1986–2020) visualizes the Adjusted Close price, highlighting the asset's growth trajectory and volatility regimes. A subsequent pairplot (on the 2014–2019 subset, the timeframe these models will train on) examines the distributional relationships between variables, aiding in the detection of outliers or structural breaks.\n",
        "\n",
        "## Experimental Design & Segmentation\n",
        "To facilitate the walk-forward validation strategy, the data is partitioned into strict chronological segments, maintaining consistency across models for direct comparability. The timeline is effectively truncated to start from 2014 to focus on modern market dynamics and ended before 2019, to exculde post COVID volatility.\n",
        "* **Training/Validation Split:** Data prior to 2018 is designated for training, with 2018 serving as the validation period for hyperparameter tuning.\n",
        "* **Test Split:** Data from 2019 is held out as the unseen test set for final model evaluation.\n",
        "* **Standardization:** The dataset is formally restructured into the `ds` (datestamp) and `y` (target variable) format required by the Prophet library, establishing a \"Master Dataset\" from which all subsequent model-specific subsets are derived."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4bd7fe2",
      "metadata": {
        "id": "d4bd7fe2"
      },
      "outputs": [],
      "source": [
        "## Data Preprocessing ##\n",
        "# Basic prep\n",
        "adbe_df['Date'] = pd.to_datetime(adbe_df['Date'], dayfirst=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c1e9b6",
      "metadata": {
        "id": "65c1e9b6"
      },
      "outputs": [],
      "source": [
        "# Check data quality\n",
        "assert adbe_df['Adjusted Close'].notna().all(), \"Missing values found\"\n",
        "assert (adbe_df['Adjusted Close'] > 0).all(), \"Non-positive prices found\"\n",
        "assert (adbe_df['Date']).duplicated().sum() == 0, \"Duplicate dates found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b54f7b3",
      "metadata": {
        "id": "9b54f7b3",
        "outputId": "092f05c7-a17d-4701-e9d7-8cabdf538313"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nTotal data: {len(adbe_df)} observations\")\n",
        "print(f\"Date range: {adbe_df['Date'].iloc[0].date()} to {adbe_df['Date'].iloc[-1].date()}\")\n",
        "print(f\"Price range: ${adbe_df['Adjusted Close'].min():.2f} - ${adbe_df['Adjusted Close'].max():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "295445e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the total number of dates available in the dataset\n",
        "start_date = adbe_df['Date'].min()\n",
        "end_date = adbe_df['Date'].max()\n",
        "\n",
        "print(f\"Date range: {start_date} to {end_date}\")\n",
        "\n",
        "# Calculate the total number of calendar days in the timeline\n",
        "full_timeline = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "total_calendar_days = len(full_timeline)\n",
        "\n",
        "# Calculate the number of days available in the dataset\n",
        "available_data_days = len(adbe_df)\n",
        "print(f\"Total calendar days in the timeline: {total_calendar_days}\")\n",
        "print(f\"Number of days with available data: {available_data_days}\")\n",
        "\n",
        "# Calculate the number of weekends in the timeline\n",
        "number_of_weekends = sum(full_timeline.dayofweek >= 5)\n",
        "print(f\"Number of weekend days (Sat/Sun): {number_of_weekends}\")\n",
        "\n",
        "# Calculate the number of holidays for the period\n",
        "year_list = range(start_date.year, end_date.year + 1)\n",
        "holidays_df = make_holidays_df(year_list=year_list, country='US')\n",
        "\n",
        "# Filter holidays to be within the timeline and not on a weekend\n",
        "holidays_in_timeline = holidays_df[(holidays_df['ds'] >= start_date) & (holidays_df['ds'] <= end_date) & (holidays_df['ds'].dt.dayofweek < 5)]\n",
        "number_of_holidays = len(holidays_in_timeline)\n",
        "print(f\"Number of public holiday weekdays: {number_of_holidays}\")\n",
        "\n",
        "# find the days that are missing on the dataset\n",
        "missing_days = total_calendar_days - available_data_days - number_of_weekends - number_of_holidays\n",
        "print(f\"Missing days in the dataset: {missing_days}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4cd9cad",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the 'Adjusted Close' price against the 'Date'\n",
        "plt.plot(adbe_df['Date'], adbe_df['Adjusted Close'])\n",
        "\n",
        "# Add a title and labels\n",
        "plt.title('Adobe (ADBE) Adjusted Close Price Over Time (1986-2020)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Adjusted Close Price (USD)')\n",
        "\n",
        "# Add a grid for easier analysis\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af92844",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter a range for model training\n",
        "start_date = '2014-01-01'\n",
        "end_date = '2019-12-31'\n",
        "\n",
        "# Filter ADBE stock\n",
        "adbe_df = adbe_df[(adbe_df['Date'] >= start_date) & (adbe_df['Date'] <= end_date)].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9e7f8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.pairplot(adbe_df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3489176d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the strict timelines\n",
        "START_DATE = '2014-01-01'\n",
        "VAL_START  = '2018-01-01'\n",
        "TEST_START = '2019-01-01'\n",
        "\n",
        "# Load and Filter Raw Data\n",
        "# Assuming 'adbe_df' is your initial dataframe loaded from CSV\n",
        "df_master = adbe_df[(adbe_df['Date'] >= START_DATE)].copy()\n",
        "df_master = df_master[['Date', 'Adjusted Close']].rename(columns={'Date': 'ds', 'Adjusted Close': 'y'})\n",
        "df_master = df_master.sort_values('ds').reset_index(drop=True)\n",
        "\n",
        "print(f\"Master Dataset Range: {df_master['ds'].min().date()} to {df_master['ds'].max().date()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f35508b",
      "metadata": {},
      "source": [
        "# Prophet Baseline Model (Model 1)\n",
        "\n",
        "## Feature Engineering & Transformation\n",
        "The first modeling phase establishes a univariate statistical baseline using the Prophet algorithm. To address the heteroscedasticity (varying volatility) inherent in financial time series, the target variable-Adjusted Close price is log-transformed using `np.log1p`. This transformation stabilizes the variance and compresses the range of the data, allowing the additive model to better capture trends without being distorted by the magnitude of recent prices.\n",
        "\n",
        "## Hyperparameter Optimization via Optuna\n",
        "To maximize predictive performance, the model's configuration is tuned using the Optuna optimization framework. The search space explores critical hyperparameters that control the model's flexibility:\n",
        "* **Changepoint Prior:** Regulates how sensitive the trend is to changes (preventing overfitting to noise).\n",
        "* **Seasonality & Holiday Priors:** Controls the influence of periodic cycles and holiday events.\n",
        "* **Seasonality Mode:** determines whether seasonal effects are constant (additive) or grow with the trend (multiplicative).\n",
        "However horizon is directly comparable to N-HITS' output chunk growth, and therefore both is kept at 60 days, not inputting in the hyperparameter. Both of these determine how many days into the future the models are optimized for training, and therefore kept same to make them directly comparable.\n",
        "\n",
        "The optimization process minimizes the Root Mean Squared Error (RMSE) over a rolling 60-day cross-validation horizon, identifying the parameter set that offers the best stability and generalizability.\n",
        "\n",
        "## Final Training & Evaluation\n",
        "Upon identifying the optimal hyperparameters, the final model is trained on the combined training and validation sets, augmented with a custom quarterly seasonality component to capture earnings-cycle effects. Performance is rigorously evaluated using cross-validation. Crucially, all forecast outputs are inversely transformed (`np.expm1`) back to the original dollar scale before metrics are calculated. This ensures that the reported MAE, RMSE, and MAPE reflect true dollar-value errors, providing a transparent assessment of the model's real-world accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bdba4cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Tune and Train Model 1 ##\n",
        "#  Log transformation.\n",
        "print(f\"\\n{'='*30}\\nCREATING DF: PROPHET MODEL 1\\n{'='*30}\")\n",
        "\n",
        "df_p1 = df_master.copy()\n",
        "df_p1['y'] = np.log1p(df_p1['y']) \n",
        "\n",
        "# Split\n",
        "p1_train = df_p1[df_p1['ds'] < VAL_START].copy()\n",
        "p1_val   = df_p1[(df_p1['ds'] >= VAL_START) & (df_p1['ds'] < TEST_START)].copy()\n",
        "p1_test  = df_p1[df_p1['ds'] >= TEST_START].copy()\n",
        "\n",
        "prophet_train_log = pd.concat([p1_train, p1_val]).reset_index(drop=True)\n",
        "\n",
        "print(f\"Train: {p1_train.shape[0]} | Val: {p1_val.shape[0]} | Test: {p1_test.shape[0]}\")\n",
        "print(\"Features: ['ds', 'y'] (Log Scale)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5df71aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make holidays DataFrame for US\n",
        "holidays = make_holidays_df(year_list=range(1986, 2022), country='US')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bad2413",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PARAMETERS & STORAGE\n",
        "# ============================================================================\n",
        "initial_train_size = p1_train.shape[0]\n",
        "metrics_1 = {'mae': [], 'rmse': [], 'mape': [], 'r2': []}\n",
        "\n",
        "# ============================================================================\n",
        "# OPTUNA OBJECTIVE (TUNING HORIZON + PARAMS)\n",
        "# ============================================================================\n",
        "def objective(trial):\n",
        "    # 1. Take a fixed horizon of 60 days\n",
        "    cv_horizon = 60\n",
        "    \n",
        "    # 2. Suggest Hyperparameters\n",
        "    params = {\n",
        "        'changepoint_prior_scale': trial.suggest_float('changepoint_prior_scale', 0.001, 0.5, log=True),\n",
        "        'seasonality_prior_scale': trial.suggest_float('seasonality_prior_scale', 0.01, 10.0, log=True),\n",
        "        'holidays_prior_scale': trial.suggest_float('holidays_prior_scale', 0.01, 10.0, log=True),\n",
        "        'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative'])\n",
        "    }\n",
        "\n",
        "    m = Prophet(\n",
        "        **params,\n",
        "        daily_seasonality=False,\n",
        "        weekly_seasonality=True,\n",
        "        yearly_seasonality=True,\n",
        "        holidays=holidays,\n",
        "        uncertainty_samples=1000,\n",
        "        interval_width=0.95\n",
        "    )\n",
        "    m.add_seasonality(name='quarterly', period=91.3, fourier_order=5)\n",
        "    m.fit(prophet_train_log)\n",
        "\n",
        "    # 3. Cross-Validation using the trial's horizon\n",
        "    df_cv_trial = cross_validation(\n",
        "        m,\n",
        "        initial=f'{initial_train_size} days',\n",
        "        horizon=f'{cv_horizon} days',\n",
        "        period=f'{cv_horizon} days', # Jump by the horizon to avoid overlap\n",
        "        parallel=\"processes\"\n",
        "    )\n",
        "\n",
        "    print(f\"  Total predictions made: {len(df_cv_trial)}\")\n",
        "\n",
        "    # Scored on Log Scale \n",
        "    rmse_val = np.sqrt(mean_squared_error(df_cv_trial['y'], df_cv_trial['yhat']))\n",
        "    return rmse_val\n",
        "\n",
        "# ============================================================================\n",
        "# RUN TUNING\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\\nRUNNING OPTUNA: TUNING HORIZON & PARAMS\\n{'='*70}\")\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20) \n",
        "\n",
        "best_params_prophet = study.best_params\n",
        "best_horizon = 60\n",
        "\n",
        "print(best_params_prophet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f228c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINAL EVALUATION WITH BEST PARAMS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\\nRUNNING FINAL EVALUATION\\n{'='*70}\")\n",
        "\n",
        "# 1. Re-instantiate model with best parameters found by Optuna\n",
        "horizon = 60\n",
        "model_params = {k: v for k, v in study.best_params.items() if k != 'horizon'}\n",
        "\n",
        "model_1_prophet = Prophet(\n",
        "    **model_params,\n",
        "    daily_seasonality=False,\n",
        "    weekly_seasonality=True,\n",
        "    yearly_seasonality=True,\n",
        "    holidays=holidays, # Ensure 'holidays' df is defined in your previous cells\n",
        "    uncertainty_samples=1000,\n",
        "    interval_width=0.95\n",
        ")\n",
        "model_1_prophet.add_seasonality(name='quarterly', period=91.3, fourier_order=5)\n",
        "model_1_prophet.fit(prophet_train_log) # Fit on the log-transformed data\n",
        "\n",
        "# 2. Run Final Cross-Validation to get the 'df_cv' dataframe\n",
        "print(f\"Running CV with best horizon: {horizon} days...\")\n",
        "df_cv = cross_validation(\n",
        "    model_1_prophet,\n",
        "    initial=f'{initial_train_size} days',\n",
        "    horizon=f'{horizon} days',\n",
        "    period=f'{horizon} days',\n",
        "    parallel=\"processes\"\n",
        ")\n",
        "\n",
        "# Reverse log transformation for actual scale metrics\n",
        "df_cv['y_actual'] = np.expm1(df_cv['y'])\n",
        "df_cv['yhat_actual'] = np.expm1(df_cv['yhat'])\n",
        "df_cv['yhat_lower_actual'] = np.expm1(df_cv['yhat_lower'])\n",
        "df_cv['yhat_upper_actual'] = np.expm1(df_cv['yhat_upper'])\n",
        "\n",
        "# Store predictions dataframe\n",
        "predictions_cv_no_regressors = df_cv.copy()\n",
        "\n",
        "# Calculate metrics in original scale\n",
        "mae = mean_absolute_error(df_cv['y_actual'], df_cv['yhat_actual'])\n",
        "rmse = np.sqrt(mean_squared_error(df_cv['y_actual'], df_cv['yhat_actual']))\n",
        "# Added small epsilon (1e-8) to avoid division by zero\n",
        "mape = np.mean(np.abs((df_cv['y_actual'] - df_cv['yhat_actual']) / (df_cv['y_actual'] + 1e-8))) * 100\n",
        "r2 = r2_score(df_cv['y_actual'], df_cv['yhat_actual'])\n",
        "\n",
        "# Coverage analysis (The \"In-Interval\" check)\n",
        "in_interval = np.sum((df_cv['y_actual'] >= df_cv['yhat_lower_actual']) & \n",
        "                     (df_cv['y_actual'] <= df_cv['yhat_upper_actual']))\n",
        "coverage_pct = (in_interval / len(df_cv)) * 100\n",
        "avg_width_pct = np.mean((df_cv['yhat_upper_actual'] - df_cv['yhat_lower_actual']) / \n",
        "                        df_cv['y_actual']) * 100\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"\\n{'='*20} FINAL RESULTS {'='*20}\")\n",
        "print(f\"Best Horizon Used: {best_horizon} days\")\n",
        "print(f\"Number of iterations completed: { (len(prophet_train_log) - initial_train_size) // best_horizon}\")\n",
        "print(f\"MAE:  ${mae:.2f}\")\n",
        "print(f\"RMSE: ${rmse:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(f\"Prediction Interval Coverage: {coverage_pct:.2f}%\")\n",
        "print(f\"Average Interval Width:       {avg_width_pct:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4789071",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize all the components of the dataset\n",
        "forecast_model_1 = model_1_prophet.predict(prophet_train_log)\n",
        "\n",
        "figure_1 = model_1_prophet.plot_components(forecast_model_1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9441f10f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# We can change 'mape' to 'rmse', 'mae', or 'mape'.\n",
        "figure_2 = plot_cross_validation_metric(df_cv, metric='rmse')\n",
        "plt.title(\"Cross-Validation: RMSE vs. Horizon\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b30bbfa",
      "metadata": {},
      "source": [
        "# Prophet with Autoregressive Regressors Model (Model 2)\n",
        "\n",
        "## Feature Engineering Strategy\n",
        "This iteration enhances the statistical baseline by incorporating exogenous variables (regressors) to capture market momentum and volatility. The model moves beyond simple trend extrapolation by engineering specific features derived from the log-transformed price history:\n",
        "* **Autoregressive Lags:** `lag1` and `lag7` capture immediate and weekly dependencies.\n",
        "* **Technical Indicators:** A 30-day Simple Moving Average (`sma_30`) and Rolling Volatility (`volatility_30`) provide context on the asset's current regime (e.g., high vs. low variance).\n",
        "* **Trend Strength:** A derived feature measuring the deviation of the current price from its moving average.\n",
        "\n",
        "## Optimized Walk-Forward Validation\n",
        "To validate a model dependent on yesterday's price, a standard cross-validation split is insufficient. This section implements a custom **Walk-Forward Validation** loop  that strictly simulates a daily trading scenario.\n",
        "\n",
        "The validation process employs a \"Teacher Forcing\" mechanism:\n",
        "1. **Iterative Prediction:** For every day in the validation set, the model predicts the next day's value.\n",
        "2. **History Update:** Immediately after prediction, the *actual* observed price for that day is appended to the history.\n",
        "3. **Regressor Recalculation:** All features (lags, averages) are re-computed dynamically based on this updated history before the next prediction is made.\n",
        "\n",
        "This approach prevents \"error accumulation\" (where a bad prediction ruins the next day's input) and ensures the performance metrics reflect the model's accuracy in a realistic, daily-update setting.\n",
        "\n",
        "## Final Evaluation & Retraining\n",
        "Performance metrics (RMSE, MAE, Coverage) are aggregated across all sliding windows, providing a robust estimate of the model's stability. As with the previous model, all predictions are inversely transformed to dollar values for final reporting. Concluding this stage, the model is fully retrained on the combined training and validation datasets, locking in the optimized parameters (from Optuna) and the learned regressor coefficients for the final test phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc9da7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Tune and Train Model 2 ##\n",
        "# Log transform FIRST, then calculate regressors on the logged data.\n",
        "print(f\"\\n{'='*30}\\nCREATING DF: PROPHET MODEL 2\\n{'='*30}\")\n",
        "\n",
        "df_p2 = df_master.copy()\n",
        "df_p2['y'] = np.log1p(df_p2['y']) \n",
        "\n",
        "# 2. Create Features \n",
        "# These are calculated on the whole timeline to ensure continuity at split boundaries\n",
        "df_p2['lag1'] = df_p2['y'].shift(1)\n",
        "df_p2['lag7'] = df_p2['y'].shift(7)\n",
        "df_p2['sma_30'] = df_p2['y'].rolling(window=30).mean().shift(1)\n",
        "df_p2['volatility_30'] = df_p2['y'].rolling(window=30).std().shift(1)\n",
        "df_p2['trend_strength'] = df_p2['y'].shift(1) - df_p2['sma_30']\n",
        "\n",
        "# Drop the initial 30 days of NaNs created by rolling windows\n",
        "df_p2 = df_p2.dropna().reset_index(drop=True)\n",
        "\n",
        "# Split\n",
        "p2_train = df_p2[df_p2['ds'] < VAL_START].copy()\n",
        "p2_val   = df_p2[(df_p2['ds'] >= VAL_START) & (df_p2['ds'] < TEST_START)].copy()\n",
        "p2_test  = df_p2[df_p2['ds'] >= TEST_START].copy()\n",
        "\n",
        "prophet_train_regressors = pd.concat([p2_train, p2_val]).reset_index(drop=True)\n",
        "\n",
        "print(f\"Train: {p2_train.shape[0]} | Val: {p2_val.shape[0]} | Test: {p2_test.shape[0]}\")\n",
        "print(\"Features: ['ds', 'y', 'lag1', 'lag7', 'sma_30', 'volatility_30', 'trend_strength']\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b84d266a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# WALK-FORWARD VALIDATION \n",
        "# ============================================================================\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 1. Setup Parameters from Optuna\n",
        "prophet_params = {k: v for k, v in best_params_prophet.items() if k != 'horizon'}\n",
        "cv_horizon = 60\n",
        "\n",
        "# Define Validation Loop\n",
        "train_end = initial_train_size\n",
        "n_iterations = (len(prophet_train_regressors) - train_end) // cv_horizon\n",
        "all_fold_forecasts = []\n",
        "metrics = {'mae': [], 'rmse': [], 'mape': [], 'r2': []}\n",
        "coverage_metrics = {'in_coverage': [], 'coverage_width': []}\n",
        "all_predictions_list = []\n",
        "\n",
        "print(f\"\\n{'='*70}\\nRUNNING WALK-FORWARD VALIDATION WITH BEST PARAMS\\n{'='*70}\")\n",
        "print(f\"Horizon: {cv_horizon} days | Iterations: {n_iterations}\")\n",
        "\n",
        "# 2. Main Loop\n",
        "for i in range(n_iterations):\n",
        "    # A. Define current training and testing windows\n",
        "    current_train = prophet_train_regressors.iloc[:train_end].copy()\n",
        "    val_start = train_end\n",
        "    val_end = min(train_end + cv_horizon, len(prophet_train_regressors))\n",
        "    val_df = prophet_train_regressors.iloc[val_start:val_end].copy()\n",
        "\n",
        "    if len(val_df) == 0:\n",
        "        break\n",
        "\n",
        "    print(f\"Iteration {i+1}/{n_iterations}: Training on {len(current_train)} pts, Testing on {len(val_df)} pts\")\n",
        "\n",
        "    # B. Feature Engineering (Recalculated every loop to avoid leakage)\n",
        "    current_train_clean = current_train[['ds', 'y']].copy()\n",
        "    \n",
        "    # -- Lags --\n",
        "    current_train_clean['lag1'] = current_train_clean['y'].shift(1)\n",
        "    current_train_clean['lag7'] = current_train_clean['y'].shift(7)\n",
        "    \n",
        "    # -- Rolling Stats --\n",
        "    current_train_clean['sma_30'] = current_train_clean['y'].rolling(window=30, min_periods=1).mean()\n",
        "    current_train_clean['volatility_30'] = current_train_clean['y'].rolling(window=30, min_periods=1).std()\n",
        "    current_train_clean['trend_strength'] = current_train_clean['y'] - current_train_clean['sma_30']\n",
        "\n",
        "    # -- Drop NaN rows created by lags --\n",
        "    current_train_clean = current_train_clean.dropna()\n",
        "\n",
        "    if len(current_train_clean) < 50:\n",
        "        print(\"   Insufficient training data. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # C. Initialize Model with OPTUNA PARAMS\n",
        "    model_2_prophet = Prophet(\n",
        "        **prophet_params,  \n",
        "        daily_seasonality=False,\n",
        "        weekly_seasonality=True,\n",
        "        yearly_seasonality=True,\n",
        "        uncertainty_samples=1000,\n",
        "        interval_width=0.95,\n",
        "        holidays=holidays\n",
        "    )\n",
        "\n",
        "    # Add Regressors & Custom Seasonality\n",
        "    regressors = ['lag1', 'lag7', 'sma_30', 'volatility_30', 'trend_strength']\n",
        "    for reg in regressors:\n",
        "        model_2_prophet.add_regressor(reg)\n",
        "    \n",
        "    model_2_prophet.add_seasonality(name='quarterly', period=91.3, fourier_order=5)\n",
        "\n",
        "    model_2_prophet.fit(current_train_clean)\n",
        "\n",
        "    # D. Step-by-Step Prediction (Simulating Daily Trading)\n",
        "    history_y = current_train_clean['y'].values.tolist()\n",
        "    fold_predictions = []\n",
        "    actual_dates = val_df['ds'].values\n",
        "\n",
        "    for step in range(len(val_df)):\n",
        "        # Create single-row future dataframe\n",
        "        future_step_df = pd.DataFrame({'ds': [actual_dates[step]]})\n",
        "\n",
        "        # Calculate regressors based on history (Teacher Forcing: using known past)\n",
        "        history_array = np.array(history_y)\n",
        "        \n",
        "        # Safe indexing for lags\n",
        "        future_step_df['lag1'] = history_array[-1]\n",
        "        future_step_df['lag7'] = history_array[-7] if len(history_array) >= 7 else history_array[0]\n",
        "        future_step_df['sma_30'] = history_array[-30:].mean() if len(history_array) >= 30 else history_array.mean()\n",
        "        future_step_df['volatility_30'] = np.std(history_array[-30:]) if len(history_array) >= 30 else 0\n",
        "        \n",
        "        sma_current = future_step_df['sma_30'].values[0]\n",
        "        future_step_df['trend_strength'] = history_array[-1] - sma_current\n",
        "\n",
        "        # Predict\n",
        "        forecast_step = model_2_prophet.predict(future_step_df)\n",
        "        fold_predictions.append(forecast_step)\n",
        "\n",
        "        # Update history with the ACTUAL value (simulating end of day)\n",
        "        actual_log_value = val_df.iloc[step]['y']\n",
        "        history_y.append(actual_log_value)\n",
        "\n",
        "    # E. Process Fold Results\n",
        "    fold_forecast_df = pd.concat(fold_predictions).reset_index(drop=True)\n",
        "    all_fold_forecasts.append(fold_forecast_df)\n",
        "\n",
        "    # Reverse Transforms\n",
        "    y_true_orig = np.expm1(val_df['y'].values)\n",
        "    y_pred_orig = np.expm1(fold_forecast_df['yhat'].values)\n",
        "    y_lower_orig = np.expm1(fold_forecast_df['yhat_lower'].values)\n",
        "    y_upper_orig = np.expm1(fold_forecast_df['yhat_upper'].values)\n",
        "\n",
        "    # Store for global visualization\n",
        "    for j in range(len(val_df)):\n",
        "        all_predictions_list.append({\n",
        "            'ds': val_df.iloc[j]['ds'],\n",
        "            'y_actual': y_true_orig[j],\n",
        "            'y_pred': y_pred_orig[j],\n",
        "            'y_lower': y_lower_orig[j],\n",
        "            'y_upper': y_upper_orig[j],\n",
        "            'fold': i + 1\n",
        "        })\n",
        "\n",
        "    # Calculate Metrics\n",
        "    mae = mean_absolute_error(y_true_orig, y_pred_orig)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
        "    mape = np.mean(np.abs((y_true_orig - y_pred_orig) / (y_true_orig + 1e-8))) * 100\n",
        "    r2 = r2_score(y_true_orig, y_pred_orig)\n",
        "    \n",
        "    # Coverage\n",
        "    in_interval = np.sum((y_true_orig >= y_lower_orig) & (y_true_orig <= y_upper_orig))\n",
        "    coverage = (in_interval / len(y_true_orig)) * 100\n",
        "    avg_width_pct = np.mean((y_upper_orig - y_lower_orig) / y_true_orig) * 100\n",
        "\n",
        "    metrics['mae'].append(mae)\n",
        "    metrics['rmse'].append(rmse)\n",
        "    metrics['mape'].append(mape)\n",
        "    metrics['r2'].append(r2)\n",
        "    coverage_metrics['in_coverage'].append(coverage)\n",
        "    coverage_metrics['coverage_width'].append(avg_width_pct)\n",
        "    \n",
        "    print(f\"    RMSE: ${rmse:.2f} | MAPE: {mape:.2f}% | Coverage: {coverage:.1f}%\")\n",
        "\n",
        "    # Move sliding window\n",
        "    train_end += cv_horizon\n",
        "\n",
        "# 3. Final Report\n",
        "print(f\"\\n{'='*70}\\nFINAL CROSS-VALIDATION RESULTS (OPTIMIZED)\\n{'='*70}\")\n",
        "print(f\"Average MAE:   ${np.mean(metrics['mae']):.2f}\")\n",
        "print(f\"Average RMSE:  ${np.mean(metrics['rmse']):.2f}\")\n",
        "print(f\"Average MAPE:  {np.mean(metrics['mape']):.2f}%\")\n",
        "print(f\"Average R²:    {np.mean(metrics['r2']):.4f}\")\n",
        "print(f\"Avg Coverage:  {np.mean(coverage_metrics['in_coverage']):.1f}% (Target: 95%)\")\n",
        "print(f\"Avg Width:     {np.mean(coverage_metrics['coverage_width']):.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "661f4aff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINAL TRAINING: MODEL 2 (Train + Val)\n",
        "# ============================================================================\n",
        "# 1. Prepare the Combined Dataset (Train + Val)\n",
        "prophet_train_regressors = pd.concat([p2_train, p2_val]).reset_index(drop=True)\n",
        "\n",
        "print(f\"Combined Data for Training: {len(prophet_train_regressors)} rows\")\n",
        "print(f\"Date Range: {prophet_train_regressors['ds'].min()} to {prophet_train_regressors['ds'].max()}\")\n",
        "\n",
        "# 2. Re-initialize the model\n",
        "model_2_prophet = Prophet(\n",
        "    **prophet_params,  # Uses your Optuna best params\n",
        "    daily_seasonality=False,\n",
        "    weekly_seasonality=True,\n",
        "    yearly_seasonality=True,\n",
        "    uncertainty_samples=1000,\n",
        "    interval_width=0.95,\n",
        "    holidays=holidays\n",
        ")\n",
        "\n",
        "# 3. Re-add regressors & seasonality\n",
        "regressors = ['lag1', 'lag7', 'sma_30', 'volatility_30', 'trend_strength']\n",
        "for reg in regressors:\n",
        "    model_2_prophet.add_regressor(reg)\n",
        "\n",
        "model_2_prophet.add_seasonality(name='quarterly', period=91.3, fourier_order=5)\n",
        "\n",
        "# 4. Fit on combined history\n",
        "print(\"Fitting Model 2 on Train+Val data...\")\n",
        "model_2_prophet.fit(prophet_train_regressors)\n",
        "print(\"✅ Model 2 training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989d4b52",
      "metadata": {},
      "source": [
        "# Comparative Evaluation & Benchmarking\n",
        "\n",
        "## Baseline Establishment: The Persistence Model\n",
        "To rigorously assess the value of the advanced models, a \"Persistence\" (or Naive) baseline is established. This simple heuristic assumes that *tomorrow's price will equal today's price* ($y_{t+1} = y_t$). In financial forecasting, this is a notoriously difficult benchmark to beat due to the random walk nature of asset prices.\n",
        "* **Vectorized Implementation:** A baseline dataframe is created by shifting the log-transformed target variable by one timestep.\n",
        "* **Validation:** The persistence logic is first tested on the validation set to establish a minimum performance threshold (MAE, RMSE) that any complex model must surpass to justify its complexity.\n",
        "\n",
        "## Benchmark 1: Static Forecasting (Model 1 vs. Static Persistence)\n",
        "This section evaluates the first Prophet model (univariate) against a **Static Persistence** baseline on the unseen test set.\n",
        "* **Experimental Design:** The evaluation tests multiple time horizons ranging from 7 days to 365 days.\n",
        "* **Static Assumption:** For the baseline, the price at the *start* of the test period is projected forward as a flat line for the entire horizon.\n",
        "* **Metric Comparison:** The code iterates through each horizon, calculating error metrics (MAE, RMSE, MAPE) and prediction interval coverage. A summary table quantifies the percentage improvement (or degradation) of the Prophet model compared to this static baseline, revealing the model's ability to capture trend versus a flat line.\n",
        "\n",
        "## Benchmark 2: Dynamic Forecasting (Model 2 vs. Rolling Persistence)\n",
        "The final evaluation tests the second Prophet model (with regressors) in a realistic \"day trading\" simulation against a **Rolling Persistence** baseline.\n",
        "* **Rolling Prediction Loop:** A leakage-proof loop generates 1-step-ahead predictions. For each day in the test set, the model utilizes the full history up to that point (including the previous day's actual price) to predict the current day.\n",
        "* **Rolling Baseline:** The persistence model is updated daily, always predicting the next value based on the most recent observation.\n",
        "* **Performance Analysis:** Cumulative metrics are calculated for expanding windows (7 days, 14 days, etc.). This comparison is critical as it determines if the complex model adds value over simply following the most recent market price. A positive \"Improvement %\" here indicates genuine predictive skill beyond the random walk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5189dd5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Training persistence model\n",
        "print(f\"\\n{'='*70}\\nPERSISTENCE MODEL EVALUATION\\n{'='*70}\")\n",
        "\n",
        "# 1. Generate predictions for the ENTIRE dataset at once\n",
        "df_persistence = prophet_train_log.copy()\n",
        "df_persistence['y_pred_log'] = df_persistence['y'].shift(1)\n",
        "\n",
        "# 2. Slice the \"Validation\" portion only\n",
        "val_df = df_persistence.iloc[initial_train_size:].copy()\n",
        "\n",
        "# 3. Reverse Log Transform to get Real Prices ($)\n",
        "y_true = np.expm1(val_df['y'])\n",
        "y_pred = np.expm1(val_df['y_pred_log'])\n",
        "\n",
        "# 4. Calculate Overall Metrics\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "# Added epsilon to avoid potential division by zero\n",
        "mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(f\"MAE:  ${mae:.2f}\")\n",
        "print(f\"RMSE: ${rmse:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "\n",
        "# 5. Store for visualization comparison later\n",
        "predictions_df_persistence = val_df[['ds']].copy()\n",
        "predictions_df_persistence['y_actual'] = y_true\n",
        "predictions_df_persistence['y_pred'] = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5104a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MODEL 1 TEST SET EVALUATION (STATIC PERSISTENCE BASELINE)\n",
        "# ============================================================================\n",
        "print(f\"\\nTesting Prophet Model 1 on {len(p1_test)} test data points\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Define horizons to test\n",
        "horizons = [7, 14, 30, 60, 91, 183, 252, 365]\n",
        "\n",
        "# Storage for results\n",
        "horizon_results_p1 = []\n",
        "\n",
        "for horizon in horizons:\n",
        "    # Check if we have enough test data for this horizon\n",
        "    if horizon > len(p1_test):\n",
        "        print(f\"Skipping horizon {horizon} - insufficient test data\")\n",
        "        continue\n",
        "\n",
        "    # Get test subset for this horizon\n",
        "    test_subset = p1_test.iloc[:horizon].copy()\n",
        "\n",
        "    # Model 1 Prediction\n",
        "    forecast_test = model_1_prophet.predict(test_subset)\n",
        "\n",
        "    # Transform predictions\n",
        "    y_true = np.expm1(test_subset['y'].values)\n",
        "    y_pred = np.expm1(forecast_test['yhat'].values)\n",
        "    y_lower = np.expm1(forecast_test['yhat_lower'].values)\n",
        "    y_upper = np.expm1(forecast_test['yhat_upper'].values)\n",
        "\n",
        "    # Persistence Prediction (static)\n",
        "    last_known_log = p1_test['y'].iloc[0] \n",
        "    y_pred_pers = np.full(horizon, np.expm1(last_known_log))\n",
        "\n",
        "    # Calculate metrics for Model 1\n",
        "    mae_model = mean_absolute_error(y_true, y_pred)\n",
        "    rmse_model = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape_model = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n",
        "    r2_model = r2_score(y_true, y_pred)\n",
        "\n",
        "    # Coverage metrics\n",
        "    in_interval = np.sum((y_true >= y_lower) & (y_true <= y_upper))\n",
        "    coverage_pct = (in_interval / len(y_true)) * 100\n",
        "    avg_width_pct = np.mean((y_upper - y_lower) / y_true) * 100\n",
        "\n",
        "    # Calculate metrics for Persistence\n",
        "    mae_pers = mean_absolute_error(y_true, y_pred_pers)\n",
        "    rmse_pers = np.sqrt(mean_squared_error(y_true, y_pred_pers))\n",
        "    mape_pers = np.mean(np.abs((y_true - y_pred_pers) / (y_true + 1e-8))) * 100\n",
        "    r2_pers = r2_score(y_true, y_pred_pers)\n",
        "\n",
        "    # Store results\n",
        "    horizon_results_p1.append({\n",
        "        'horizon': horizon,\n",
        "        'mae_model': mae_model,\n",
        "        'rmse_model': rmse_model,\n",
        "        'mape_model': mape_model,\n",
        "        'r2_model': r2_model,\n",
        "        'coverage': coverage_pct,\n",
        "        'avg_width': avg_width_pct,\n",
        "        'mae_pers': mae_pers,\n",
        "        'rmse_pers': rmse_pers,\n",
        "        'mape_pers': mape_pers,\n",
        "        'r2_pers': r2_pers\n",
        "    })\n",
        "\n",
        "    # Print results for this horizon\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"HORIZON: {horizon} days\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"\\n{'Model 1 (Prophet)':>20} | {'Persistence':>20}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    print(f\"{'MAE:':<15} {mae_model:>12.3f} | {mae_pers:>20.3f}\")\n",
        "    print(f\"{'RMSE:':<15} {rmse_model:>12.3f} | {rmse_pers:>20.3f}\")\n",
        "    print(f\"{'MAPE:':<15} {mape_model:>11.2f}% | {mape_pers:>19.2f}%\")\n",
        "    print(f\"{'R²:':<15} {r2_model:>12.4f} | {r2_pers:>20.4f}\")\n",
        "    print(f\"\\n{'Prophet Coverage:':<25} {coverage_pct:.1f}%\")\n",
        "    print(f\"{'Prophet Avg Width:':<25} {avg_width_pct:.1f}%\")\n",
        "\n",
        "# Create summary DataFrame\n",
        "results_df_1 = pd.DataFrame(horizon_results_p1)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SUMMARY: Model 1 vs Persistence Across All Horizons\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "print(results_df_1.to_string(index=False))\n",
        "\n",
        "# Calculate improvement percentages\n",
        "results_df_1['mae_improvement'] = ((results_df_1['mae_pers'] - results_df_1['mae_model']) / results_df_1['mae_pers']) * 100\n",
        "results_df_1['rmse_improvement'] = ((results_df_1['rmse_pers'] - results_df_1['rmse_model']) / results_df_1['rmse_pers']) * 100\n",
        "results_df_1['mape_improvement'] = ((results_df_1['mape_pers'] - results_df_1['mape_model']) / results_df_1['mape_pers']) * 100\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"IMPROVEMENT OF MODEL 1 OVER PERSISTENCE (% better)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "print(results_df_1[['horizon', 'mae_improvement', 'rmse_improvement', 'mape_improvement']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1bc765",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MODEL 2 (Autoregressive) vs ROLLING PERSISTENCE \n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"Generating 1-step-ahead (Non-Recursive) predictions via LEAKAGE-PROOF LOOP\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Concatenate Train, Val, and Test sets\n",
        "full_history_log_2 = pd.concat([p2_train, p2_val, p2_test]).reset_index(drop=True)\n",
        "\n",
        "test_start_index = len(p2_train) + len(p2_val)\n",
        "model_2_nr_predictions = []\n",
        "\n",
        "# Loop through the TEST portion of the full history\n",
        "for i in range(test_start_index, len(full_history_log_2)):\n",
        "    \n",
        "    # A. The specific day we want to predict\n",
        "    future_step_df = pd.DataFrame({'ds': [full_history_log_2.iloc[i]['ds']]})\n",
        "    \n",
        "    # B. Strict History Isolation: Get all data UP TO yesterday \n",
        "    history_array = full_history_log_2.iloc[:i]['y'].values\n",
        "    \n",
        "    # C. Calculate Regressors \n",
        "    future_step_df['lag1'] = history_array[-1]\n",
        "    future_step_df['lag7'] = history_array[-7]\n",
        "    future_step_df['sma_30'] = history_array[-30:].mean()\n",
        "    future_step_df['volatility_30'] = np.std(history_array[-30:])\n",
        "    future_step_df['trend_strength'] = history_array[-1] - history_array[-30:].mean()\n",
        "    \n",
        "    # D. Predict\n",
        "    forecast_step = model_2_prophet.predict(future_step_df)\n",
        "    model_2_nr_predictions.append(forecast_step)\n",
        "\n",
        "# Store predictions\n",
        "forecast_df_nr = pd.concat(model_2_nr_predictions).reset_index(drop=True)\n",
        "\n",
        "test_predictions_model_2_nr = pd.DataFrame({\n",
        "    'ds': p2_test['ds'].reset_index(drop=True),\n",
        "    'y_actual': np.expm1(p2_test['y'].reset_index(drop=True)),\n",
        "    'y_pred': np.expm1(forecast_df_nr['yhat'].reset_index(drop=True)),\n",
        "    'yhat_lower': np.expm1(forecast_df_nr['yhat_lower'].reset_index(drop=True)),\n",
        "    'yhat_upper': np.expm1(forecast_df_nr['yhat_upper'].reset_index(drop=True))\n",
        "})\n",
        "\n",
        "print(\"1-step-ahead predictions generated.\")\n",
        "\n",
        "# ============================================================================\n",
        "# PERSISTENCE \n",
        "# ============================================================================\n",
        "last_val_value = p2_val['y'].iloc[-1] \n",
        "y_pred_log_pers = p2_test['y'].shift(1).fillna(last_val_value)\n",
        "\n",
        "test_predictions_persistence = pd.DataFrame({\n",
        "    'ds': p2_test['ds'].reset_index(drop=True),\n",
        "    'y_actual': np.expm1(p2_test['y'].reset_index(drop=True)),\n",
        "    'y_pred': np.expm1(y_pred_log_pers.reset_index(drop=True))\n",
        "})\n",
        "\n",
        "print(\"Persistence predictions generated.\")\n",
        "\n",
        "# ============================================================================\n",
        "# COMPARISON METRICS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Comparing Model 2 (Non-Recursive) vs. Persistence (Rolling)\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "model_2_results = test_predictions_model_2_nr.copy()\n",
        "persistence_results = test_predictions_persistence.copy()\n",
        "\n",
        "max_days = len(model_2_results)\n",
        "horizons = [7, 14, 30, 60, 91, 183, 251]\n",
        "if max_days not in horizons and max_days > 183:\n",
        "    horizons.append(max_days)\n",
        "\n",
        "horizon_results_p2 = []\n",
        "\n",
        "for horizon in horizons:\n",
        "    if horizon > max_days: continue\n",
        "\n",
        "    # Slice data\n",
        "    model_2_slice = model_2_results.iloc[:horizon]\n",
        "    persistence_slice = persistence_results.iloc[:horizon]\n",
        "\n",
        "    y_true = model_2_slice['y_actual'].values\n",
        "    \n",
        "    # Model 2 Metrics\n",
        "    y_pred_m2 = model_2_slice['y_pred'].values\n",
        "    y_lower = model_2_slice['yhat_lower'].values\n",
        "    y_upper = model_2_slice['yhat_upper'].values\n",
        "    \n",
        "    mae_model = mean_absolute_error(y_true, y_pred_m2)\n",
        "    rmse_model = np.sqrt(mean_squared_error(y_true, y_pred_m2))\n",
        "    mape_model = np.mean(np.abs((y_true - y_pred_m2) / (y_true + 1e-8))) * 100\n",
        "    r2_model = r2_score(y_true, y_pred_m2)\n",
        "    \n",
        "    in_interval = np.sum((y_true >= y_lower) & (y_true <= y_upper))\n",
        "    coverage_pct = (in_interval / len(y_true)) * 100\n",
        "    avg_width_pct = np.mean((y_upper - y_lower) / y_true) * 100\n",
        "    \n",
        "    # Persistence Metrics\n",
        "    y_pred_pers = persistence_slice['y_pred'].values\n",
        "    \n",
        "    mae_pers = mean_absolute_error(y_true, y_pred_pers)\n",
        "    rmse_pers = np.sqrt(mean_squared_error(y_true, y_pred_pers))\n",
        "    mape_pers = np.mean(np.abs((y_true - y_pred_pers) / (y_true + 1e-8))) * 100\n",
        "    r2_pers = r2_score(y_true, y_pred_pers)\n",
        "    \n",
        "    # Store\n",
        "    horizon_results_p2.append({\n",
        "        'horizon': horizon,\n",
        "        'mae_model': mae_model, 'rmse_model': rmse_model, 'mape_model': mape_model, 'r2_model': r2_model,\n",
        "        'coverage': coverage_pct, 'avg_width': avg_width_pct,\n",
        "        'mae_pers': mae_pers, 'rmse_pers': rmse_pers, 'mape_pers': mape_pers, 'r2_pers': r2_pers\n",
        "    })\n",
        "    \n",
        "    # Print\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"HORIZON: {horizon} days (Cumulative)\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{'Metric':<15} | {'Model 2 (Non-Recursive)':>25} | {'Persistence (Rolling)':>25}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    print(f\"{'MAE:':<15} | {mae_model:>25.3f} | {mae_pers:>25.3f}\")\n",
        "    print(f\"{'RMSE:':<15} | {rmse_model:>25.3f} | {rmse_pers:>25.3f}\")\n",
        "    print(f\"{'MAPE:':<15} | {mape_model:>24.2f}% | {mape_pers:>24.2f}%\")\n",
        "    print(f\"{'R²:':<15} | {r2_model:>25.4f} | {r2_pers:>25.4f}\")\n",
        "    print(f\"\\n{'Model 2 Coverage:':<25} {coverage_pct:.1f}%\")\n",
        "    print(f\"{'Model 2 Avg Width:':<25} {avg_width_pct:.1f}%\")\n",
        "\n",
        "# Summary Table\n",
        "results_df_2 = pd.DataFrame(horizon_results_p2)\n",
        "results_df_2['mae_improvement'] = ((results_df_2['mae_pers'] - results_df_2['mae_model']) / results_df_2['mae_pers']) * 100\n",
        "results_df_2['rmse_improvement'] = ((results_df_2['rmse_pers'] - results_df_2['rmse_model']) / results_df_2['rmse_pers']) * 100\n",
        "results_df_2['mape_improvement'] = ((results_df_2['mape_pers'] - results_df_2['mape_model']) / results_df_2['mape_pers']) * 100\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"IMPROVEMENT OF MODEL 2 OVER ROLLING PERSISTENCE (% better)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "print(results_df_2[['horizon', 'mae_improvement', 'rmse_improvement', 'mape_improvement']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3dd725c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZATION: TEST SET RESULTS\n",
        "# ============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prepare Model 1 Data\n",
        "forecast_m1_full = model_1_prophet.predict(p1_test)\n",
        "m1_dates = p1_test['ds']\n",
        "m1_actual = np.expm1(p1_test['y'])\n",
        "m1_pred = np.expm1(forecast_m1_full['yhat'])\n",
        "m1_static_pers = np.full(len(p1_test), np.expm1(p1_test['y'].iloc[0]))\n",
        "\n",
        "\n",
        "# PLOT 1: Model 1 vs Static Persistence\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.plot(m1_dates, m1_actual, label='Actual', color='yellow', alpha=0.6, linewidth=2)\n",
        "plt.plot(m1_dates, m1_pred, label='Model 1 (Prophet)', color='orange', alpha=0.8, linewidth=1.5)\n",
        "plt.plot(m1_dates, m1_static_pers, label='Static Persistence (Baseline)', color='green', linestyle='--', alpha=0.8, linewidth=1.5)\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price ($)')\n",
        "plt.title('Test Result: Model 1 vs. Static Persistence (2019)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# PLOT 2: Model 2 vs Rolling Persistence\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.plot(test_predictions_model_2_nr['ds'], test_predictions_model_2_nr['y_actual'], label='Actual', color='yellow', alpha=0.6, linewidth=2)\n",
        "plt.plot(test_predictions_model_2_nr['ds'], test_predictions_model_2_nr['y_pred'], label='Model 2 (Non-Recursive)', color='red', alpha=0.8, linewidth=1.5)\n",
        "plt.plot(test_predictions_persistence['ds'], test_predictions_persistence['y_pred'], label='Rolling Persistence (Baseline)', color='blue', linestyle='--', alpha=0.6, linewidth=1.5)\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price ($)')\n",
        "plt.title('Test Result: Model 2 vs. Rolling Persistence (2019)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7968959",
      "metadata": {},
      "source": [
        "# Model Serialization & State Persistence\n",
        "\n",
        "## Artifact Storage & Reproducibility\n",
        "To ensure operational efficiency and prevent the need for computationally expensive retraining, this section implements a robust serialization pipeline. The finalized model states and optimization results are persisted to disk using a lightweight JSON format.\n",
        "* **Hyperparameters:** The optimal configuration dictionary derived from the Optuna study is saved as `best_params_prophet.json`.\n",
        "* **Model Objects:** Both the univariate (Model 1) and multivariate (Model 2) Prophet estimators are serialized using Prophet's native `model_to_json` utility. This captures the learned parameters (trends, seasonality coefficients) and the internal state required to generate future forecasts.\n",
        "\n",
        "## State Verification\n",
        "A comprehensive deserialization test is immediately executed to validate the integrity of the saved artifacts. The code reloads the parameters and model objects from the disk into memory and performs a status check, confirming that the forecasting engine can be successfully restored and deployed in a production environment without data loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "485b951f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from prophet.serialize import model_to_json\n",
        "\n",
        "# ============================================================================\n",
        "# SAVE OPTUNA PARAMETERS \n",
        "# ============================================================================\n",
        "# Save best params to a JSON file\n",
        "with open('best_params_prophet.json', 'w') as f:\n",
        "    json.dump(best_params_prophet, f)\n",
        "print(\"✅ Optuna parameters saved to 'best_params_prophet.json'\")\n",
        "\n",
        "# ============================================================================\n",
        "# SAVE TRAINED MODELS \n",
        "# ============================================================================\n",
        "# Save Model 1\n",
        "with open('model_1_prophet.json', 'w') as fout:\n",
        "    json.dump(model_to_json(model_1_prophet), fout)\n",
        "print(\"✅ Model 1 saved to 'model_1_prophet.json'\")\n",
        "\n",
        "# Save Model 2\n",
        "with open('model_2_prophet.json', 'w') as fout:\n",
        "    json.dump(model_to_json(model_2_prophet), fout)\n",
        "print(\"✅ Model 2 saved to 'model_2_prophet.json'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21cd494d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from prophet.serialize import model_from_json\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD EVERYTHING BACK\n",
        "# ============================================================================\n",
        "\n",
        "# Load Optuna Parameters \n",
        "with open('best_params_prophet.json', 'r') as f:\n",
        "    best_params_prophet = json.load(f)\n",
        "\n",
        "# Load Model 1 \n",
        "with open('model_1_prophet.json', 'r') as f:\n",
        "    model_1_prophet = model_from_json(json.load(f))\n",
        "\n",
        "# Load Model 2 \n",
        "with open('model_2_prophet.json', 'r') as f:\n",
        "    model_2_prophet = model_from_json(json.load(f))\n",
        "\n",
        "# ============================================================================\n",
        "# VERIFICATION\n",
        "# ============================================================================\n",
        "print(\"✅ Loaded Successfully!\")\n",
        "print(f\"Best Params: {best_params_prophet}\")\n",
        "print(f\"Model 1 Status: {'Ready' if model_1_prophet else 'Failed'}\")\n",
        "print(f\"Model 2 Status: {'Ready' if model_2_prophet else 'Failed'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de26e34b",
      "metadata": {},
      "source": [
        "# N-HITS Model (Neural Network)\n",
        "\n",
        "## Feature Scaling & Transformation\n",
        "Deep neural networks are highly sensitive to the magnitude of input data. To ensure stable gradient descent and convergence, this section implements a rigorous preprocessing pipeline specifically designed for the N-HiTS architecture.\n",
        "* **Log-Transformation:** The raw Adjusted Close prices are first transformed using `np.log1p`. This compresses the exponential growth trend of the asset and stabilizes the variance, making the data more homoscedastic.\n",
        "* **MinMax Scaling:** Following the log transform, the data is normalized to a strict `[0, 1]` range using `MinMaxScaler`. This prevents the \"exploding gradient\" problem common in networks processing raw financial values.\n",
        "* **Leakage Prevention:** Critically, the scaler is fitted **only on the training partition**. The validation and test sets are transformed using the statistics derived solely from the training past, ensuring no information from the future leaks into the scaling parameters.\n",
        "\n",
        "## Darts Framework Integration\n",
        "The processed dataframes are converted into `TimeSeries` objects, the native data structure for the Darts forecasting library. A key design choice here is the use of **integer indexing** rather than datetime indexing. By treating the data as a sequence of logical steps (0, 1, 2...), the model effectively \"glues\" Friday to Monday, removing the noise of weekend gaps and allowing the neural network to focus purely on the sequence of trading activity.\n",
        "\n",
        "## Data Integrity Verification\n",
        "Before being fed into the neural network, the tensors undergo a final diagnostic check. A custom diagnostic function validates the `TimeSeries` objects to ensure:\n",
        "* **Structural Correctness:** confirming the correct shape and `float32` data type.\n",
        "* **Sanity Checks:** verifying the absence of `NaN` or `Inf` values that could cause training instability.\n",
        "* **Scaling Verification:** confirming that the training data successfully resides within the expected bounds (min/max/mean) post-transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba0506d0",
      "metadata": {
        "id": "ba0506d0",
        "outputId": "7b2603aa-286c-4bf3-ad44-f6267d6a1706"
      },
      "outputs": [],
      "source": [
        "## Training and Tuning N-HITS Model ##\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "import numpy as np\n",
        "\n",
        "print(f\"\\n{'='*30}\\nCREATING BRANCH: N-HITS\\n{'='*30}\")\n",
        "\n",
        "# 1. Split RAW Data (Keep these safe for ground truth comparisons later)\n",
        "nhits_train_raw = df_master[df_master['ds'] < VAL_START].copy()\n",
        "nhits_val_raw   = df_master[(df_master['ds'] >= VAL_START) & (df_master['ds'] < TEST_START)].copy()\n",
        "nhits_test_raw  = df_master[df_master['ds'] >= TEST_START].copy()\n",
        "\n",
        "# 2. Apply Log Transform (np.log1p)\n",
        "nhits_train_log = nhits_train_raw.copy()\n",
        "nhits_val_log   = nhits_val_raw.copy()\n",
        "nhits_test_log  = nhits_test_raw.copy()\n",
        "\n",
        "nhits_train_log['y'] = np.log1p(nhits_train_raw['y'])\n",
        "nhits_val_log['y']   = np.log1p(nhits_val_raw['y'])\n",
        "nhits_test_log['y']  = np.log1p(nhits_test_raw['y'])\n",
        "\n",
        "# 3. Initialize Scaler & Fit on TRAIN LOG Data ONLY\n",
        "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
        "scaler.fit(nhits_train_log[['y']]) \n",
        "\n",
        "# 4. Transform All Sets (Log -> MinMax Scaled)\n",
        "nhits_train_scaled = nhits_train_log.copy()\n",
        "nhits_val_scaled   = nhits_val_log.copy()\n",
        "nhits_test_scaled  = nhits_test_log.copy()\n",
        "\n",
        "nhits_train_scaled['y'] = scaler.transform(nhits_train_log[['y']])\n",
        "nhits_val_scaled['y']   = scaler.transform(nhits_val_log[['y']])\n",
        "nhits_test_scaled['y']  = scaler.transform(nhits_test_log[['y']])\n",
        "\n",
        "print(f\"Train: {nhits_train_scaled.shape[0]} | Val: {nhits_val_scaled.shape[0]} | Test: {nhits_test_scaled.shape[0]}\")\n",
        "print(f\"Scaler Stats (From Train Log): Min={scaler.data_min_[0]:.4f}, Max={scaler.data_max_[0]:.4f}\")\n",
        "print(\"Features: ['ds', 'y'] (MinMax Scaled)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10201f2",
      "metadata": {
        "id": "d10201f2",
        "outputId": "f106e42f-c01d-4dff-86c0-be7a9124443c"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CREATE DARTS TIMESERIES \n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"LOADING EXISTING SPLITS INTO DARTS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Map specific 'Branch 3' variables to generic names\n",
        "train_df = nhits_train_scaled\n",
        "val_df   = nhits_val_scaled\n",
        "test_df  = nhits_test_scaled\n",
        "\n",
        "print(f\"Using Master Split Data:\")\n",
        "print(f\"Train: {len(train_df)} rows\")\n",
        "print(f\"Val:   {len(val_df)} rows\")\n",
        "print(f\"Test:  {len(test_df)} rows\")\n",
        "\n",
        "# Create TimeSeries (Gap-Free Integer Indexing)\n",
        "train_series = TimeSeries.from_dataframe(train_df, value_cols='y').astype(np.float32)\n",
        "val_series   = TimeSeries.from_dataframe(val_df, value_cols='y').astype(np.float32)\n",
        "test_series  = TimeSeries.from_dataframe(test_df, value_cols='y').astype(np.float32)\n",
        "\n",
        "print(\"✅ Darts TimeSeries created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "746dcea8",
      "metadata": {
        "id": "746dcea8",
        "outputId": "1d722ad7-e99d-487d-fac6-792291e0410c"
      },
      "outputs": [],
      "source": [
        "# Save original prices\n",
        "\n",
        "train_prices = nhits_train_raw['y'].values\n",
        "val_prices   = nhits_val_raw['y'].values\n",
        "test_prices  = nhits_test_raw['y'].values\n",
        "\n",
        "print(f\"Test Start Price: ${test_prices[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befd4bed",
      "metadata": {
        "id": "befd4bed",
        "outputId": "ee71352b-12b1-4c2c-fed6-f18240c1edea"
      },
      "outputs": [],
      "source": [
        "# Diagnose Darts TimeSeries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def diagnose_series(ts, name):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"DIAGNOSIS: {name}\")\n",
        "    print(f\"{'='*40}\")\n",
        "\n",
        "    # 1. Get underlying values \n",
        "    vals = ts.values()\n",
        "\n",
        "    # 2. Check basics\n",
        "    print(f\"Shape: {vals.shape}\")\n",
        "    print(f\"Type:  {vals.dtype}\")\n",
        "\n",
        "    # 3. Check for Corruption (NaNs / Infs)\n",
        "    n_nans = np.isnan(vals).sum()\n",
        "    n_infs = np.isinf(vals).sum()\n",
        "\n",
        "    print(f\"NaN Count: {n_nans}\")\n",
        "    print(f\"Inf Count: {n_infs}\")\n",
        "\n",
        "    if n_nans > 0:\n",
        "        print(\"⚠️  LOCATIONS OF NaNs:\")\n",
        "        # Find indices of NaNs\n",
        "        nan_indices = np.where(np.isnan(vals))[0]\n",
        "        print(f\"   Indices: {nan_indices[:10]} ... (showing first 10)\")\n",
        "        # Note: Since we are using Integer Indexing, ts.time_index will just be integers\n",
        "        print(f\"   Indices (Time): {ts.time_index[nan_indices[:10]]}\")\n",
        "\n",
        "    # 4. Check Range (Data should be approx Mean=0, Std=1 if scaled)\n",
        "    if n_nans == 0 and n_infs == 0:\n",
        "        print(f\"Min Value: {vals.min():.6f}\")\n",
        "        print(f\"Max Value: {vals.max():.6f}\")\n",
        "        print(f\"Mean:      {vals.mean():.6f} (Should be close to 0)\")\n",
        "        print(f\"Std Dev:   {vals.std():.6f}  (Should be close to 1)\")\n",
        "    else:\n",
        "        print(\"❌ Cannot compute Range/Mean because data contains NaNs/Infs\")\n",
        "\n",
        "    # 5. Inspect First & Last 5 Rows\n",
        "    print(\"\\nFirst 5 Values:\")\n",
        "    print(vals[:5].flatten())\n",
        "    print(\"Last 5 Values:\")\n",
        "    print(vals[-5:].flatten())\n",
        "\n",
        "# ============================================================================\n",
        "# RUN DIAGNOSIS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Checking Darts TimeSeries objects\")\n",
        "\n",
        "# 1. Check Train\n",
        "diagnose_series(train_series, \"train_series\")\n",
        "\n",
        "# 2. Check Val\n",
        "diagnose_series(val_series, \"val_series\")\n",
        "\n",
        "# 3. Check Test\n",
        "diagnose_series(test_series, \"test_series\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cbdd41f",
      "metadata": {},
      "source": [
        "# Hyperparameter Tuning & Architecture Search\n",
        "\n",
        "## Automated Optimization Strategy\n",
        "To determine the optimal neural architecture, the analysis employs **Optuna**, a define-by-run optimization framework. The search strategy utilizes the **Tree-structured Parzen Estimator (TPE)** sampler, a Bayesian approach that models the probability of parameters improving the objective function, rather than simple random search. To maximize computational efficiency, a **Median Pruner** is implemented to automatically terminate unpromising trials early (if their intermediate loss exceeds the median of previous trials), allocating resources only to high-potential configurations. The study is configured to run for 50 trials or a maximum of 2 hours.\n",
        "\n",
        "## Performance Analysis & Selection\n",
        "Post-optimization, the workflow strictly separates successful trials from converged failures (infinity loss). The results are statistically analyzed to assess stability, reporting the mean, median, and standard deviation of the validation RMSE across all valid trials. The single best configuration, minimizing the validation error, is extracted to define the final model structure.\n",
        "\n",
        "## Artifact Persistence & Visualization\n",
        "To ensure reproducibility and allow for later inspection, the entire optimization study is serialized to disk (`joblib`), along with a lightweight JSON file containing only the best parameters. Finally, the optimization process is visualized through three diagnostic plots:\n",
        "* **Optimization History:** Tracks the convergence of the objective value over time.\n",
        "* **Parameter Importance:** Quantifies which hyperparameters (e.g., learning rate, input chunk length) had the most significant impact on model performance. \n",
        "* **Parallel Coordinates:** Visualizes the high-dimensional relationships and trade-offs between different parameter combinations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f31b705",
      "metadata": {
        "id": "2f31b705"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Define device explicitly so the code knows what to use\n",
        "device = \"gpu\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3c907a2",
      "metadata": {
        "id": "d3c907a2"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# High-Performance Objective Function\n",
        "# ============================================================================\n",
        "from darts.metrics import rmse as darts_rmse\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # ========================================================================\n",
        "    # HYPERPARAMETER SAMPLING \n",
        "    # ========================================================================\n",
        "    num_stacks = trial.suggest_int('num_stacks', 2, 4)\n",
        "\n",
        "    input_chunk_length = trial.suggest_int('input_chunk_length', 30, 120)  \n",
        "    output_chunk_length = 60 # kept similar to prophet\n",
        "    num_blocks = trial.suggest_int('num_blocks', 1, 3)  \n",
        "    num_layers = trial.suggest_int('num_layers', 2, 4)\n",
        "    layer_width = trial.suggest_int('layer_width', 128, 512)\n",
        "\n",
        "    # Full dropout range \n",
        "    dropout = trial.suggest_float('dropout', 0.0, 0.3)  \n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # Standard learning rate range \n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-3, log=True)\n",
        "\n",
        "    # Derived parameters\n",
        "    layer_widths = [layer_width] * num_stacks\n",
        "    pooling_kernel_sizes = [[2] * num_blocks for _ in range(num_stacks)]\n",
        "    n_freq_downsample = [\n",
        "        [2 ** (num_stacks - i - 1)] * num_blocks\n",
        "        for i in range(num_stacks)\n",
        "    ]\n",
        "\n",
        "    # ========================================================================\n",
        "    # MODEL CONFIGURATION\n",
        "    # ========================================================================\n",
        "    model = NHiTSModel(\n",
        "        input_chunk_length=input_chunk_length,\n",
        "        output_chunk_length=60,\n",
        "        num_stacks=num_stacks,\n",
        "        num_blocks=num_blocks,\n",
        "        num_layers=num_layers,\n",
        "        layer_widths=layer_widths,\n",
        "        pooling_kernel_sizes=pooling_kernel_sizes,\n",
        "        n_freq_downsample=n_freq_downsample,\n",
        "        dropout=dropout,\n",
        "        batch_size=batch_size,\n",
        "        n_epochs=100,  \n",
        "        optimizer_kwargs={\n",
        "            'lr': learning_rate,\n",
        "            'weight_decay': 1e-4,  # L2 regularization \n",
        "        },\n",
        "        random_state=42,\n",
        "        force_reset=True,\n",
        "        save_checkpoints=False,\n",
        "        log_tensorboard=False,\n",
        "        pl_trainer_kwargs={\n",
        "            \"accelerator\": \"cpu\",\n",
        "            \"enable_progress_bar\": False,\n",
        "            \"enable_model_summary\": False,\n",
        "            \"gradient_clip_val\": 1.0,  # Standard clipping \n",
        "            \n",
        "            \"callbacks\": [\n",
        "                EarlyStopping(\n",
        "                    monitor='train_loss',\n",
        "                    patience=10,\n",
        "                    min_delta=0.0001,\n",
        "                    mode='min'\n",
        "                )\n",
        "        ],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # ========================================================================\n",
        "    # TRAINING & VALIDATION\n",
        "    # ========================================================================\n",
        "    try:\n",
        "        model.fit(train_series, verbose=False)\n",
        "\n",
        "        # Context-based validation\n",
        "        val_context = train_series.append(val_series)\n",
        "\n",
        "        forecasts = model.historical_forecasts(\n",
        "            series=val_context,\n",
        "            start=len(train_series),\n",
        "            forecast_horizon=output_chunk_length,\n",
        "            stride=output_chunk_length,  # Non-overlapping\n",
        "            retrain=False,\n",
        "            verbose=False,\n",
        "            last_points_only=False\n",
        "        )\n",
        "\n",
        "        if len(forecasts) == 0:\n",
        "            print(f\"Trial {trial.number}: ❌ Failed (0 forecasts)\")\n",
        "            return float('inf')\n",
        "\n",
        "        # Compute RMSE\n",
        "        scores = []\n",
        "        for forecast in forecasts:\n",
        "            actual = val_series.slice_intersect(forecast)\n",
        "            if len(actual) > 0:\n",
        "                score = darts_rmse(actual, forecast)\n",
        "                if not (np.isnan(score) or np.isinf(score)):\n",
        "                    scores.append(score)\n",
        "\n",
        "        if not scores:\n",
        "            print(f\"Trial {trial.number}: ❌ Failed (No valid scores)\")\n",
        "            return float('inf')\n",
        "\n",
        "        final_score = np.mean(scores)\n",
        "\n",
        "        if np.isnan(final_score) or np.isinf(final_score):\n",
        "            print(f\"Trial {trial.number}: ❌ Failed (Result was NaN/Inf)\")\n",
        "            return float('inf')\n",
        "\n",
        "        # ✅ SUCCESS LOGGING\n",
        "        print(f\"Trial {trial.number}: ✅ RMSE = {final_score:.6f}\")\n",
        "        return final_score\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Trial {trial.number}: ❌ Crashed: {e}\")\n",
        "        return float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1deb65",
      "metadata": {
        "id": "3d1deb65",
        "outputId": "267d88c8-e7a4-4daa-e744-d0f9d7f8d1f6"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# RUN OPTIMIZATION\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"HYPERPARAMETER OPTIMIZATION\")\n",
        "print(f\"{'='*70}\")\n",
        "# Suppress verbose logging\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# Create study\n",
        "study = optuna.create_study(\n",
        "    direction='minimize',\n",
        "    sampler=optuna.samplers.TPESampler(\n",
        "        seed=42,\n",
        "        n_startup_trials=15,  # Random search for first 15 trials\n",
        "        multivariate=True     # Consider parameter interactions\n",
        "    ),\n",
        "    pruner=optuna.pruners.MedianPruner(\n",
        "        n_startup_trials=15,  # Don't prune first 15 trials\n",
        "        n_warmup_steps=5,\n",
        "        interval_steps=1\n",
        "    )\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "study.optimize(\n",
        "    objective,\n",
        "    n_trials=50,\n",
        "    timeout=2*60*60,  # 2 hours max\n",
        "    show_progress_bar=True,\n",
        "    n_jobs=1,  # Single job \n",
        "    gc_after_trial=True  # Garbage collection after each trial\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28f7a7f",
      "metadata": {
        "id": "d28f7a7f",
        "outputId": "21c3ac87-b86d-47c4-d5dc-e982295b897d"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ANALYZE RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"OPTIMIZATION COMPLETE\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Separate successful and failed trials\n",
        "successful_trials = [t for t in study.trials if t.value != float('inf')]\n",
        "failed_trials = [t for t in study.trials if t.value == float('inf')]\n",
        "\n",
        "if len(successful_trials) > 0:\n",
        "    print(f\"Found {len(successful_trials)} stable configurations\")\n",
        "    print(f\"\\nBest validation RMSE: {study.best_value:.6f}\")\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"BEST HYPERPARAMETERS:\")\n",
        "    print(f\"{'='*50}\")\n",
        "    for key, value in study.best_params.items():\n",
        "        print(f\"  {key:25s}: {value}\")\n",
        "\n",
        "    # Show top 5 configurations\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"TOP 5 CONFIGURATIONS:\")\n",
        "    print(f\"{'='*50}\")\n",
        "    sorted_trials = sorted(successful_trials, key=lambda t: t.value)[:5]\n",
        "    for i, trial in enumerate(sorted_trials, 1):\n",
        "        print(f\"  {i}. Trial {trial.number:3d}: RMSE = {trial.value:.6f}\")\n",
        "\n",
        "    # Performance statistics\n",
        "    rmse_values = [t.value for t in successful_trials]\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"PERFORMANCE STATISTICS:\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"  Best RMSE:    {min(rmse_values):.6f}\")\n",
        "    print(f\"  Median RMSE:  {np.median(rmse_values):.6f}\")\n",
        "    print(f\"  Worst RMSE:   {max(rmse_values):.6f}\")\n",
        "    print(f\"  Mean RMSE:    {np.mean(rmse_values):.6f}\")\n",
        "    print(f\"  Std RMSE:     {np.std(rmse_values):.6f}\")\n",
        "\n",
        "else:\n",
        "    print(\"All trials failed!\")\n",
        "    print(\"Check your data preprocessing steps.\")\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"TRIAL SUMMARY:\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"  Total trials:     {len(study.trials)}\")\n",
        "print(f\"  Successful:       {len(successful_trials)} ({len(successful_trials)/len(study.trials)*100:.1f}%)\")\n",
        "print(f\"  Failed/pruned:    {len(failed_trials)} ({len(failed_trials)/len(study.trials)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d642ab8",
      "metadata": {
        "id": "6d642ab8",
        "outputId": "88fee57b-ae03-4eb6-9212-70533e9c052a"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SAVE RESULTS \n",
        "# ============================================================================\n",
        "\n",
        "import joblib\n",
        "import json\n",
        "import os\n",
        "\n",
        "if len(successful_trials) > 0:\n",
        "    # Save complete study\n",
        "    study_path = 'nhits_study_final.pkl'\n",
        "    joblib.dump(study, study_path)\n",
        "    print(f\"\\n✅ Study saved to: {os.path.abspath(study_path)}\")\n",
        "\n",
        "    # Save best parameters as JSON\n",
        "    params_path = 'best_params_nhits.json'\n",
        "    with open(params_path, 'w') as f:\n",
        "        json.dump(study.best_params, f, indent=2)\n",
        "    print(f\"✅ Best parameters saved to: {os.path.abspath(params_path)}\")\n",
        "\n",
        "    # Save summary statistics\n",
        "    summary_path = 'optimization_summary.txt'\n",
        "    with open(summary_path, 'w') as f:\n",
        "        f.write(\"NHITS HYPERPARAMETER OPTIMIZATION SUMMARY\\n\")\n",
        "        f.write(\"=\"*70 + \"\\n\\n\")\n",
        "        f.write(f\"Best RMSE (scaled): {study.best_value:.6f}\\n\\n\")\n",
        "        f.write(\"Best Hyperparameters:\\n\")\n",
        "        for key, value in study.best_params.items():\n",
        "            f.write(f\"  {key:25s}: {value}\\n\")\n",
        "        f.write(f\"\\nTrials: {len(study.trials)}\\n\")\n",
        "        f.write(f\"Successful: {len(successful_trials)}\\n\")\n",
        "        f.write(f\"Failed: {len(failed_trials)}\\n\")\n",
        "    print(f\"✅ Summary saved to: {os.path.abspath(summary_path)}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"READY FOR FINAL MODEL TRAINING ON TRAIN+VAL\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f99fab07",
      "metadata": {
        "id": "f99fab07",
        "outputId": "cc621552-7eca-4c4e-aa4a-8347f25d4a7d"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import optuna\n",
        "\n",
        "# Load the study back from the file\n",
        "study = joblib.load(\"nhits_study_final.pkl\")\n",
        "# Optimization history\n",
        "optuna.visualization.plot_optimization_history(study).show()\n",
        "\n",
        "# Parameter importances\n",
        "optuna.visualization.plot_param_importances(study).show()\n",
        "\n",
        "# Parallel coordinate plot\n",
        "optuna.visualization.plot_parallel_coordinate(study).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad40e14",
      "metadata": {},
      "source": [
        "# Final Model Training & Evaluation (N-HiTS)\n",
        "\n",
        "## Optimized Model Training\n",
        "With the optimal hyperparameters identified via Optuna, the analysis proceeds to the final production training phase. The training and validation sets are merged into a contiguous `train_val_series` to maximize the data available for the model. The N-HiTS architecture is reconstructed using the \"best\" configuration, specifically defining the number of stacks, blocks, and layer widths. The model is then fully trained on this consolidated dataset, locking in the weights that will be used for out-of-sample testing.\n",
        "\n",
        "## Dual-Strategy Forecasting\n",
        "To provide a comprehensive assessment of the model's capabilities, predictions are generated using two distinct strategies:\n",
        "* **Rolling 1-Step Forecast (Walk-Forward):** This simulates a deployed trading bot that updates daily. For every day in the test set, the model predicts the next day's close price using the full history available up to that moment. \n",
        "* **Static Multi-Horizon Forecast:** This tests the model's long-term stability by projecting the entire test period (e.g., 250+ days) from a single point in time, without any updates.\n",
        "\n",
        "Crucially, a **Reconstruction Pipeline** is implemented to map the model's raw output (which is in MinMax scaled log-space) back to interpretable dollar values. This involves applying the inverse MinMax transform followed by the inverse Log transform (`np.expm1`).\n",
        "\n",
        "## Baseline Benchmarking\n",
        "To contextualize performance, the analysis constructs rigorous baselines:\n",
        "* **Rolling Persistence:** Assumes tomorrow's price is identical to today's (the \"Random Walk\" hypothesis).\n",
        "* **Static Persistence:** Projects the last known price forward as a flat line for the entire duration.\n",
        "Overall this setup makes the results directly comparable to Prophet's results.\n",
        "\n",
        "## Stability Analysis & Visualization\n",
        "The evaluation goes beyond simple averages by implementing a **Blocked Cross-Validation** technique. The test set is divided into five chronological blocks, and the model's \"Skill\" (improvement over baseline) is calculated for each. This reveals whether the model's performance is consistent or if it degrades during specific market regimes.\n",
        "\n",
        "Finally, a suite of visualizations is generated to diagnose performance:\n",
        "* **Trend Comparison:** Overlaying Model vs. Baseline vs. Actual prices.\n",
        "* **Zoomed Views:** Inspecting high-frequency tracking in the most recent data.\n",
        "* **Scatter Plots:** Visualizing the correlation between predicted and actual returns to assess directional accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80d34cd6",
      "metadata": {
        "id": "80d34cd6",
        "outputId": "a93de8d2-dedd-434f-8dc2-c77862196157"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Preparing Final Training Dataset\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"PREPARING FINAL DATASET (TRAIN + VAL)\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# 1. Combine existing series using Darts' append()\n",
        "train_val_series = train_series.append(val_series)\n",
        "\n",
        "# 2. Test series is already ready\n",
        "final_test_series = test_series\n",
        "\n",
        "print(f\"Final Training Data: {len(train_val_series)} days\")\n",
        "print(f\"Test Data:           {len(final_test_series)} days\")\n",
        "print(\"✅ Data merged successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c42ffa2",
      "metadata": {
        "id": "6c42ffa2",
        "outputId": "3b88a4df-3647-4993-bb1b-a7222d8402d6"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TRAIN FINAL MODEL\n",
        "# ============================================================================\n",
        "import joblib\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TRAINING FINAL MODEL\")\n",
        "print(f\"{'='*70}\")\n",
        "study = joblib.load(\"nhits_study_final.pkl\")\n",
        "best_params = study.best_params\n",
        "\n",
        "# Reconstruct derived parameters\n",
        "num_stacks = best_params['num_stacks']\n",
        "num_blocks = best_params['num_blocks']\n",
        "layer_width = best_params['layer_width']\n",
        "layer_widths = [layer_width] * num_stacks\n",
        "pooling_kernel_sizes = [[2] * num_blocks for _ in range(num_stacks)]\n",
        "n_freq_downsample = [[2 ** (num_stacks - i - 1)] * num_blocks for i in range(num_stacks)]\n",
        "\n",
        "final_model = NHiTSModel(\n",
        "    input_chunk_length=best_params['input_chunk_length'],\n",
        "    output_chunk_length=60,\n",
        "    num_stacks=num_stacks,\n",
        "    num_blocks=num_blocks,\n",
        "    num_layers=best_params['num_layers'],\n",
        "    layer_widths=layer_widths,\n",
        "    pooling_kernel_sizes=pooling_kernel_sizes,\n",
        "    n_freq_downsample=n_freq_downsample,\n",
        "    dropout=best_params['dropout'],\n",
        "    batch_size=best_params['batch_size'],\n",
        "    n_epochs=100,\n",
        "    optimizer_kwargs={'lr': best_params['learning_rate'], 'weight_decay': 1e-5},\n",
        "    random_state=42,\n",
        "    force_reset=True,\n",
        "    save_checkpoints=False,\n",
        "    pl_trainer_kwargs={\n",
        "        \"accelerator\": \"cpu\",\n",
        "        \"gradient_clip_val\": 1.0,\n",
        "        \"enable_progress_bar\": True\n",
        "    }\n",
        ")\n",
        "\n",
        "final_model.fit(train_val_series, verbose=True)\n",
        "print(\"✅ Final model trained.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57ba03c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# N-HITS Cross-Validation Summary\n",
        "# ============================================================================\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"RUNNING N-HITS CROSS-VALIDATION (HISTORICAL FORECASTS)\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Run Historical Forecasts\n",
        "stride = 1\n",
        "forecast_horizon = 60\n",
        "\n",
        "print(f\"Running historical forecasts (Horizon: {forecast_horizon} days)\")\n",
        "\n",
        "cv_forecasts = final_model.historical_forecasts(\n",
        "    series=train_val_series, \n",
        "    start=len(train_series),\n",
        "    forecast_horizon=forecast_horizon,\n",
        "    stride=stride,\n",
        "    retrain=False,\n",
        "    verbose=True,\n",
        "    last_points_only=True\n",
        ")\n",
        "\n",
        "# Align Predictions with Actuals\n",
        "cv_series = TimeSeries.from_times_and_values(\n",
        "    times=cv_forecasts.time_index,\n",
        "    values=cv_forecasts.values()\n",
        ")\n",
        "\n",
        "actual_series_slice = train_val_series.slice_intersect(cv_series)\n",
        "\n",
        "preds_scaled = cv_series.values().flatten()\n",
        "actuals_scaled = actual_series_slice.values().flatten()\n",
        "\n",
        "# 3. Reverse transformation \n",
        "global_min = scaler.data_min_[0]\n",
        "global_max = scaler.data_max_[0]\n",
        "\n",
        "\n",
        "print(f\"\\ Scaler Params -> Min: {global_min:.4f}, Max: {global_max:.4f}\")\n",
        "\n",
        "def reconstruct_price(scaled_val):\n",
        "    # Formula: Value = Scaled * (Max - Min) + Min\n",
        "    log_price = scaled_val * (global_max - global_min) + global_min\n",
        "    \n",
        "    # Reverse Log to get Dollar Price\n",
        "    return np.expm1(log_price)\n",
        "\n",
        "y_hat_actual = reconstruct_price(preds_scaled)\n",
        "y_actual = reconstruct_price(actuals_scaled)\n",
        "\n",
        "# 4. CALCULATE METRICS\n",
        "mae = mean_absolute_error(y_actual, y_hat_actual)\n",
        "rmse = np.sqrt(mean_squared_error(y_actual, y_hat_actual))\n",
        "mape = np.mean(np.abs((y_actual - y_hat_actual) / (y_actual + 1e-8))) * 100\n",
        "r2 = r2_score(y_actual, y_hat_actual)\n",
        "\n",
        "# 5. PRINT RESULTS\n",
        "print(f\"\\n{'='*20} FINAL RESULTS (VALIDATION CV) {'='*20}\")\n",
        "print(f\"Best Horizon Used: {forecast_horizon} days\")\n",
        "print(f\"Number of predictions: {len(y_hat_actual)}\")\n",
        "print(f\"MAE:  ${mae:.2f}\")\n",
        "print(f\"RMSE: ${rmse:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "print(f\"R²:   {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e8fca8a",
      "metadata": {
        "id": "3e8fca8a",
        "outputId": "98172816-e8a5-403e-b8f5-64f8b03545b2"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Forecasting rolling & static on train set\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"GENERATING FORECASTS (ROLLING & STATIC)\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Prepare Full History for Rolling Forecasts\n",
        "full_series = train_val_series.append(test_series)\n",
        "\n",
        "# ROLLING 1-STEP (WALK-FORWARD)\n",
        "print(\"Generating Rolling Forecast (Continuous Walk-Forward)...\")\n",
        "pred_rolling_scaled = final_model.historical_forecasts(\n",
        "    series=full_series,\n",
        "    start=len(train_val_series),\n",
        "    forecast_horizon=1,\n",
        "    stride=1,\n",
        "    retrain=False,\n",
        "    verbose=True,\n",
        "    last_points_only=True\n",
        ")\n",
        "\n",
        "# METHOD B: STATIC MULTI-HORIZON \n",
        "print(\"Generating Static Forecast (Multi-Horizon)...\")\n",
        "pred_static_scaled = final_model.predict(\n",
        "    n=len(test_series),\n",
        "    series=train_val_series\n",
        ")\n",
        "\n",
        "# Reconstruction\n",
        "print(\"Reconstructing Prices (Inverse MinMax + Inverse Log)...\")\n",
        "\n",
        "global_min = scaler.data_min_[0]\n",
        "global_max = scaler.data_max_[0]\n",
        "\n",
        "def reconstruct_global(scaled_values):\n",
        "    \n",
        "    # Recover Log Price using MinMax formula\n",
        "    log_pred = scaled_values * (global_max - global_min) + global_min\n",
        "    \n",
        "    # Convert to Dollars (Use np.expm1)\n",
        "    return np.expm1(log_pred)\n",
        "\n",
        "# A. Reconstruct Rolling\n",
        "pred_roll_vals = pred_rolling_scaled.values().flatten()\n",
        "price_rolling = reconstruct_global(pred_roll_vals)\n",
        "\n",
        "# B. Reconstruct Static\n",
        "pred_static_vals = pred_static_scaled.values().flatten()\n",
        "price_static = reconstruct_global(pred_static_vals)\n",
        "\n",
        "print(f\"✅ Forecasts Generated & Reconstructed.\")\n",
        "print(f\"   Rolling Predictions: {len(price_rolling)}\")\n",
        "print(f\"   Static Predictions:  {len(price_static)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c692ec",
      "metadata": {
        "id": "15c692ec",
        "outputId": "bd22d7d2-199a-4597-96a5-8b95ea26709e"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CREATING BASELINES \n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"CREATING BASELINES\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# 1. Define actual prices\n",
        "actual_prices = nhits_test_raw['y'].values\n",
        "last_val_price = nhits_val_raw['y'].iloc[-1] # Last known price before test start\n",
        "\n",
        "print(f\"Test Data Shape: {len(actual_prices)} days\")\n",
        "print(f\"Last Known Price (Val): ${last_val_price:.2f}\")\n",
        "\n",
        "# 2. Convert to Series for easy shifting\n",
        "actual_series = pd.Series(actual_prices)\n",
        "\n",
        "# 3. Rolling Persistence (For comparing with Rolling N-HiTS)\n",
        "base_rolling = actual_series.shift(1).fillna(last_val_price).values\n",
        "\n",
        "# 4. Static Persistence (For comparing with Static N-HiTS)\n",
        "base_static = np.full(len(actual_prices), last_val_price)\n",
        "\n",
        "print(f\"✅ Baselines Created.\")\n",
        "print(f\"   Rolling Baseline Start: ${base_rolling[0]:.2f}\")\n",
        "print(f\"   Static Baseline Value:  ${base_static[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4caabd59",
      "metadata": {
        "id": "4caabd59",
        "outputId": "543e0249-bb34-453d-ca8d-ace4eac1ad3e"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# WFI CROSS-VALIDATION (Blocked evaluation)\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"WFI CROSS-VALIDATION (STABILITY ANALYSIS)\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Setup Blocks\n",
        "NUM_BLOCKS = 5\n",
        "block_size = len(actual_prices) // NUM_BLOCKS\n",
        "print(f\"Splitting Test Set ({len(actual_prices)} days) into {NUM_BLOCKS} Blocks of ~{block_size} days.\")\n",
        "\n",
        "block_metrics = []\n",
        "\n",
        "print(f\"{'-'*85}\")\n",
        "print(f\"{'Block':<6} {'Days':<12} {'RMSE (Roll)':<15} {'RMSE (Base)':<15} {'Skill':<10} {'Status'}\")\n",
        "print(f\"{'-'*85}\")\n",
        "\n",
        "for i in range(NUM_BLOCKS):\n",
        "    start = i * block_size\n",
        "    # Ensure last block takes the remainder\n",
        "    end = (i + 1) * block_size if i < NUM_BLOCKS - 1 else len(actual_prices)\n",
        "    \n",
        "    # Slice Data\n",
        "    b_act = actual_prices[start:end]\n",
        "    b_pred = price_rolling[start:end]\n",
        "    b_base = base_rolling[start:end]\n",
        "    \n",
        "    # Calculate RMSE\n",
        "    rmse_mod = np.sqrt(mean_squared_error(b_act, b_pred))\n",
        "    rmse_bas = np.sqrt(mean_squared_error(b_act, b_base))\n",
        "    \n",
        "    # Calculate Skill\n",
        "    skill = (1 - rmse_mod / rmse_bas) * 100\n",
        "    \n",
        "    # Status\n",
        "    status = \"Stable\" if rmse_mod < rmse_bas else \"Lagging\"\n",
        "    \n",
        "    block_metrics.append(rmse_mod)\n",
        "    print(f\"#{i+1:<5} {start}-{end:<11} ${rmse_mod:<14.2f} ${rmse_bas:<14.2f} {skill:>+6.1f}%   {status}\")\n",
        "\n",
        "# Aggregate Block Metrics\n",
        "block_metrics = np.array(block_metrics)\n",
        "print(f\"{'-'*85}\")\n",
        "print(f\"CV Summary: Mean RMSE=${block_metrics.mean():.2f} | Std RMSE=${block_metrics.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2129a067",
      "metadata": {
        "id": "2129a067",
        "outputId": "c5421f2a-e448-42c7-cf0b-c56b2022e458"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINAL AGGREGATED REPORT\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"OVERALL PERFORMANCE COMPARISON\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Helper\n",
        "def get_metrics(act, pred):\n",
        "    rmse = np.sqrt(mean_squared_error(act, pred))\n",
        "    mae = mean_absolute_error(act, pred)\n",
        "    mape = np.mean(np.abs((act - pred) / act)) * 100\n",
        "    \n",
        "    # Direction accuracy\n",
        "    d_act = np.diff(act) > 0\n",
        "    d_pred = np.diff(pred) > 0\n",
        "    acc = np.mean(d_act == d_pred) * 100\n",
        "    return rmse, mae, mape, acc\n",
        "\n",
        "# Calculate All\n",
        "m_roll = get_metrics(actual_prices, price_rolling)\n",
        "b_roll = get_metrics(actual_prices, base_rolling)\n",
        "m_stat = get_metrics(actual_prices, price_static)\n",
        "b_stat = get_metrics(actual_prices, base_static)\n",
        "\n",
        "# Print Table\n",
        "print(f\"{'Model / Baseline':<30} {'RMSE':<10} {'MAE':<10} {'MAPE':<8} {'Dir.Acc':<8}\")\n",
        "print(f\"{'-'*75}\")\n",
        "print(f\"{'N-HiTS Rolling (WFI)':<30} ${m_roll[0]:<9.2f} ${m_roll[1]:<9.2f} {m_roll[2]:>5.2f}%   {m_roll[3]:>5.1f}%\")\n",
        "print(f\"{'Persistence Rolling':<30} ${b_roll[0]:<9.2f} ${b_roll[1]:<9.2f} {b_roll[2]:>5.2f}%   {b_roll[3]:>5.1f}%\")\n",
        "print(f\"{'-'*75}\")\n",
        "print(f\"{'N-HiTS Static (Multi-Hor)':<30} ${m_stat[0]:<9.2f} ${m_stat[1]:<9.2f} {m_stat[2]:>5.2f}%   {m_stat[3]:>5.1f}%\")\n",
        "print(f\"{'Persistence Static':<30} ${b_stat[0]:<9.2f} ${b_stat[1]:<9.2f} {b_stat[2]:>5.2f}%   {b_stat[3]:>5.1f}%\")\n",
        "\n",
        "# Save CSV\n",
        "import pandas as pd\n",
        "res_df = pd.DataFrame({\n",
        "    'Date': test_df['ds'].values,\n",
        "    'Actual': actual_prices,\n",
        "    'Pred_Rolling': price_rolling,\n",
        "    'Pred_Static': price_static,\n",
        "    'Base_Rolling': base_rolling,\n",
        "    'Base_Static': base_static\n",
        "})\n",
        "res_df.to_csv('final_results_robust.csv', index=False)\n",
        "print(\"\\n✅ Results saved to 'final_results_robust.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8df34f",
      "metadata": {
        "id": "2c8df34f",
        "outputId": "a4a045ce-14f6-4977-91f0-47a2ed7155e8"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"GENERATING CHARTS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "dates = test_df['ds'].values\n",
        "\n",
        "def save_plot(filename, title):\n",
        "    plt.title(title, fontsize=20, fontweight='bold', pad=15)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price ($)')\n",
        "    plt.legend(loc='best', fontsize=14)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "    plt.gcf().set_size_inches(20, 10)\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(f\"Saved {filename}\")\n",
        "\n",
        "# 1. Rolling vs Baseline\n",
        "plt.figure()\n",
        "plt.plot(dates, actual_prices, 'k-', lw=2, alpha=0.8, label='Actual')\n",
        "plt.plot(dates, price_rolling, 'g-', lw=2, alpha=0.8, label='N-HiTS Rolling')\n",
        "plt.plot(dates, base_rolling, 'r--', lw=1.5, alpha=0.6, label='Persistence Rolling')\n",
        "save_plot('chart_1_rolling.png', 'Rolling Forecast vs Persistence')\n",
        "\n",
        "# 2. Static vs Baseline\n",
        "plt.figure()\n",
        "plt.plot(dates, actual_prices, 'k-', lw=2, alpha=0.8, label='Actual')\n",
        "plt.plot(dates, price_static, 'b-', lw=2, alpha=0.8, label='N-HiTS Static')\n",
        "plt.plot(dates, base_static, 'r--', lw=1.5, alpha=0.6, label='Persistence Static')\n",
        "save_plot('chart_2_static.png', 'Static Forecast vs Persistence')\n",
        "\n",
        "# 3. Zoom (Rolling)\n",
        "zoom = 100\n",
        "plt.figure()\n",
        "plt.plot(dates[-zoom:], actual_prices[-zoom:], 'ko-', lw=2, label='Actual')\n",
        "plt.plot(dates[-zoom:], price_rolling[-zoom:], 'gs-', lw=2, label='N-HiTS Rolling')\n",
        "plt.plot(dates[-zoom:], base_rolling[-zoom:], 'r--', lw=2, label='Persistence')\n",
        "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "save_plot('chart_3_zoom.png', f'Zoomed View (Last {zoom} Days)')\n",
        "\n",
        "# 4. Stability (Bar Chart)\n",
        "plt.figure()\n",
        "plt.bar([f\"Block {i+1}\" for i in range(NUM_BLOCKS)], block_metrics, color='purple', alpha=0.6)\n",
        "plt.axhline(block_metrics.mean(), color='k', linestyle='--', label='Mean RMSE')\n",
        "plt.ylabel('RMSE ($)')\n",
        "plt.title(f'Stability Analysis ({NUM_BLOCKS} Blocks)', fontsize=20, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.savefig('chart_4_stability.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"Saved chart_4_stability.png\")\n",
        "\n",
        "# 5. Scatter\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.scatter(actual_prices, price_rolling, alpha=0.5, c='g', s=50)\n",
        "mx = max(actual_prices.max(), price_rolling.max())\n",
        "mn = min(actual_prices.min(), price_rolling.min())\n",
        "plt.plot([mn, mx], [mn, mx], 'r--', lw=2, label='Perfect')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Prediction Accuracy', fontsize=20, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.savefig('chart_5_scatter.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"Saved chart_5_scatter.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29254496",
      "metadata": {},
      "source": [
        "# Comprehensive Benchmarking & Visualization\n",
        "\n",
        "## Forecast Generation Strategy\n",
        "To evaluate real-world applicability versus theoretical stability, the code executes two distinct forecasting protocols (same as Prophet) across multiple time horizons (ranging from 7 to 250 days):\n",
        "* **Rolling Forecasts (Active):** Simulates a high-frequency trading strategy where the model is updated daily with the latest closing price to predict the next day ($t+1$). This measures the model's ability to adapt to immediate market shifts.\n",
        "* **Static Forecasts (Passive):** Tests long-term reliability by freezing the model at the start of the test period and projecting prices deep into the future without receiving any new data. This isolates the model's ability to learn genuine structural patterns versus simply \"copying\" the last known price.\n",
        "\n",
        "## Price Reconstruction Pipeline\n",
        "Since the models operate in transformed feature spaces to facilitate learning, a crucial reconstruction step is performed before evaluation. This ensures all error metrics are calculated on the actual dollar value of the stock, enabling direct comparison.\n",
        "* **N-HiTS Reconstruction:** Inverses the MinMax scaling followed by the inverse Log transform (`np.expm1`).\n",
        "* **Prophet Reconstruction:** Inverses the Log transform.\n",
        "* **Baseline Generation:** Constructs the Naive persistence benchmarks (Rolling = shift yesterday's price; Static = horizontal line from start price).\n",
        "\n",
        "## Performance Metrics & Analysis\n",
        "Standard error metrics **RMSE** (Root Mean Squared Error), **MAE** (Mean Absolute Error), and **MAPE** (Mean Absolute Percentage Error) are computed for every model at every horizon. A summary table aggregates these results, explicitly identifying the \"Winner\" (lowest RMSE) for each timeframe to determine which approach dominates in the short, medium, and long term.\n",
        "\n",
        "## Visualization Suite\n",
        "A rich set of seven diagnostic plots is generated to scrutinize performance from multiple angles:\n",
        "* **Multi-Horizon Comparisons:** Time-series overlays showing how forecasts diverge from actuals over 7, 30, 90, and 260 days.\n",
        "* **Performance Degradation Curves:** Line charts tracking how error rates (RMSE/MAE) increase as the forecast horizon lengthens, revealing the point where models lose predictive power.\n",
        "* **Error Distributions:** Histograms analyzing the residuals to check for bias (e.g., if a model systematically over-predicts).\n",
        "* **Heatmaps & Bar Charts:** Visual summaries that allow for quick cross-model comparison across all metrics and horizons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f08935",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# GENERATE ALL FORECASTS\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"GENERATING FINAL TEST FORECASTS - MULTI-HORIZON ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Define forecast horizons to test\n",
        "HORIZONS = [7, 30, 60, 90, 180, 250] # Adjusted max to 260 (test set size)\n",
        "print(f\"Testing Static Forecasts at Horizons: {HORIZONS}\")\n",
        "\n",
        "# --- 1. N-HiTS FORECASTS ---\n",
        "print(\"\\nRunning N-HiTS Predictions...\")\n",
        "\n",
        "# Rolling (Daily Update)\n",
        "print(\"  - Rolling (1-step, daily update)...\")\n",
        "full_series = train_val_series.append(test_series)\n",
        "nhits_rolling_scaled = final_model.historical_forecasts(\n",
        "    series=full_series, \n",
        "    start=len(train_val_series), \n",
        "    forecast_horizon=1, \n",
        "    stride=1, \n",
        "    retrain=False,\n",
        "    verbose=True, \n",
        "    last_points_only=True\n",
        ")\n",
        "\n",
        "# Static (Multi-Horizon)\n",
        "print(\"  - Static (multi-horizon forecasts)...\")\n",
        "nhits_static_horizons = {}\n",
        "for h in HORIZONS:\n",
        "    if h <= len(test_series):\n",
        "        pred = final_model.predict(n=h, series=train_val_series)\n",
        "        nhits_static_horizons[h] = pred\n",
        "        print(f\"    ✓ {h}-day forecast complete\")\n",
        "    else:\n",
        "        print(f\"    ⚠ Skipping {h}-day (exceeds test length)\")\n",
        "\n",
        "# --- 2. PROPHET FORECASTS ---\n",
        "print(\"\\nRunning Prophet Predictions...\")\n",
        "\n",
        "# Rolling (With Regressors)\n",
        "print(\"  - Rolling (1-step with regressors)...\")\n",
        "prophet_rolling_df = model_2_prophet.predict(p2_test) \n",
        "prophet_rolling_log = prophet_rolling_df['yhat'].values\n",
        "\n",
        "# Static (Multi-Horizon)\n",
        "print(\"  - Static (multi-horizon forecasts)...\")\n",
        "prophet_static_horizons = {}\n",
        "for h in HORIZONS:\n",
        "    if h <= len(p1_test):\n",
        "        future = model_1_prophet.make_future_dataframe(periods=h, freq='D')\n",
        "        forecast_all = model_1_prophet.predict(future)\n",
        "        forecast_h = forecast_all.tail(h)['yhat'].values\n",
        "        prophet_static_horizons[h] = forecast_h\n",
        "        print(f\"    ✓ {h}-day forecast complete\")\n",
        "    else:\n",
        "        print(f\"    ⚠ Skipping {h}-day (exceeds test length)\")\n",
        "\n",
        "# ============================================================================\n",
        "# PRICE RECONSTRUCTION \n",
        "# ============================================================================\n",
        "print(\"\\nReconstructing Prices...\")\n",
        "\n",
        "actual_prices = nhits_test_raw['y'].values # Ground Truth (Raw Prices)\n",
        "\n",
        "# Use Min/Max attributes from the MinMaxScaler\n",
        "global_min = scaler.data_min_[0]\n",
        "global_max = scaler.data_max_[0]\n",
        "\n",
        "def recon_nhits(scaled_vals):\n",
        "    # Inverse MinMax Logic\n",
        "    log_pred = scaled_vals * (global_max - global_min) + global_min\n",
        "    \n",
        "    # Restore Inverse Log (np.expm1)\n",
        "    return np.expm1(log_pred)\n",
        "\n",
        "# Reconstruct N-HiTS Rolling\n",
        "price_nhits_rolling = recon_nhits(nhits_rolling_scaled.values().flatten())\n",
        "\n",
        "# Reconstruct N-HiTS Static\n",
        "price_nhits_static_horizons = {}\n",
        "for h, pred in nhits_static_horizons.items():\n",
        "    z_vals = pred.values().flatten()\n",
        "    price_nhits_static_horizons[h] = recon_nhits(z_vals)\n",
        "\n",
        "# Reconstruct Prophet Rolling \n",
        "price_prophet_rolling = np.expm1(prophet_rolling_log)\n",
        "\n",
        "# Reconstruct Prophet Static \n",
        "price_prophet_static_horizons = {}\n",
        "for h, pred_log in prophet_static_horizons.items():\n",
        "    price_prophet_static_horizons[h] = np.expm1(pred_log)\n",
        "\n",
        "# Persistence Baselines\n",
        "start_price = nhits_val_raw['y'].iloc[-1]\n",
        "price_base_rolling = pd.Series(actual_prices).shift(1).fillna(start_price).values\n",
        "price_base_static = np.full(len(actual_prices), start_price)\n",
        "\n",
        "# ============================================================================\n",
        "# METRICS CALCULATION\n",
        "# ============================================================================\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def get_perf(act, pred):\n",
        "    rmse = np.sqrt(mean_squared_error(act, pred))\n",
        "    mae = mean_absolute_error(act, pred)\n",
        "    mape = np.mean(np.abs((act - pred) / (act + 1e-8))) * 100\n",
        "    return rmse, mae, mape\n",
        "\n",
        "# Calculate Rolling Metrics (full test set)\n",
        "m_nh_rolling = get_perf(actual_prices, price_nhits_rolling)\n",
        "m_pr_rolling = get_perf(actual_prices, price_prophet_rolling)\n",
        "m_base_rolling = get_perf(actual_prices, price_base_rolling)\n",
        "\n",
        "# Calculate Static Metrics (for each horizon)\n",
        "m_nh_static = {}\n",
        "m_pr_static = {}\n",
        "m_base_static = {}\n",
        "\n",
        "for h in HORIZONS:\n",
        "    if h <= len(actual_prices):\n",
        "        act_h = actual_prices[:h]\n",
        "        \n",
        "        # N-HiTS\n",
        "        if h in price_nhits_static_horizons:\n",
        "            m_nh_static[h] = get_perf(act_h, price_nhits_static_horizons[h])\n",
        "        \n",
        "        # Prophet\n",
        "        if h in price_prophet_static_horizons:\n",
        "            m_pr_static[h] = get_perf(act_h, price_prophet_static_horizons[h])\n",
        "        \n",
        "        # Baseline\n",
        "        m_base_static[h] = get_perf(act_h, price_base_static[:h])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3774ef74",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DISPLAY RESULTS - ROLLING COMPARISON\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*90}\")\n",
        "print(\"ROLLING FORECASTS - FULL TEST SET COMPARISON\")\n",
        "print(f\"{'='*90}\")\n",
        "print(f\"{'MODEL':<35} | {'RMSE ($)':<12} | {'MAE ($)':<12} | {'MAPE (%)':<10}\")\n",
        "print(f\"{'-'*90}\")\n",
        "print(f\"{'N-HiTS Rolling (1-step)':<35} | {m_nh_rolling[0]:<12.2f} | {m_nh_rolling[1]:<12.2f} | {m_nh_rolling[2]:.2f}%\")\n",
        "print(f\"{'Prophet Rolling (with regressors)':<35} | {m_pr_rolling[0]:<12.2f} | {m_pr_rolling[1]:<12.2f} | {m_pr_rolling[2]:.2f}%\")\n",
        "print(f\"{'Persistence Rolling (baseline)':<35} | {m_base_rolling[0]:<12.2f} | {m_base_rolling[1]:<12.2f} | {m_base_rolling[2]:.2f}%\")\n",
        "print(f\"{'='*90}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# DISPLAY RESULTS - STATIC MULTI-HORIZON COMPARISON\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*90}\")\n",
        "print(\"STATIC FORECASTS - MULTI-HORIZON COMPARISON\")\n",
        "print(f\"{'='*90}\")\n",
        "\n",
        "for h in HORIZONS:\n",
        "    if h in m_nh_static and h in m_pr_static:\n",
        "        print(f\"\\n{'='*90}\")\n",
        "        print(f\"HORIZON: {h} DAYS\")\n",
        "        print(f\"{'='*90}\")\n",
        "        print(f\"{'MODEL':<35} | {'RMSE ($)':<12} | {'MAE ($)':<12} | {'MAPE (%)':<10}\")\n",
        "        print(f\"{'-'*90}\")\n",
        "        print(f\"{'N-HiTS Static':<35} | {m_nh_static[h][0]:<12.2f} | {m_nh_static[h][1]:<12.2f} | {m_nh_static[h][2]:.2f}%\")\n",
        "        print(f\"{'Prophet Static':<35} | {m_pr_static[h][0]:<12.2f} | {m_pr_static[h][1]:<12.2f} | {m_pr_static[h][2]:.2f}%\")\n",
        "        print(f\"{'Persistence Static':<35} | {m_base_static[h][0]:<12.2f} | {m_base_static[h][1]:<12.2f} | {m_base_static[h][2]:.2f}%\")\n",
        "        print(f\"{'-'*90}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY TABLE - SIDE BY SIDE COMPARISON\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*120}\")\n",
        "print(\"COMPREHENSIVE SUMMARY - ALL HORIZONS & METHODS\")\n",
        "print(f\"{'='*120}\")\n",
        "print(f\"{'Horizon':<12} | {'Method':<10} | {'N-HiTS RMSE':<14} | {'Prophet RMSE':<14} | {'Baseline RMSE':<14} | {'Winner':<15}\")\n",
        "print(f\"{'-'*120}\")\n",
        "\n",
        "print(f\"{'Full Set':<12} | {'Rolling':<10} | ${m_nh_rolling[0]:<13.2f} | ${m_pr_rolling[0]:<13.2f} | ${m_base_rolling[0]:<13.2f} | \", end='')\n",
        "rolling_rmses = [m_nh_rolling[0], m_pr_rolling[0], m_base_rolling[0]]\n",
        "rolling_winner = ['N-HiTS', 'Prophet', 'Baseline'][np.argmin(rolling_rmses)]\n",
        "print(f\"{rolling_winner:<15}\")\n",
        "\n",
        "for h in HORIZONS:\n",
        "    if h in m_nh_static and h in m_pr_static:\n",
        "        print(f\"{f'{h} days':<12} | {'Static':<10} | ${m_nh_static[h][0]:<13.2f} | ${m_pr_static[h][0]:<13.2f} | ${m_base_static[h][0]:<13.2f} | \", end='')\n",
        "        static_rmses = [m_nh_static[h][0], m_pr_static[h][0], m_base_static[h][0]]\n",
        "        static_winner = ['N-HiTS', 'Prophet', 'Baseline'][np.argmin(static_rmses)]\n",
        "        print(f\"{static_winner:<15}\")\n",
        "\n",
        "print(f\"{'='*120}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff9326a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# COMPREHENSIVE VISUALIZATION SUITE - MULTI-HORIZON FORECAST ANALYSIS\n",
        "# ============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "# Configure plot aesthetics\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams.update({\n",
        "    'figure.facecolor': 'white',\n",
        "    'axes.facecolor': 'white',\n",
        "    'font.size': 11,\n",
        "    'axes.labelsize': 12,\n",
        "    'axes.titlesize': 14,\n",
        "    'xtick.labelsize': 10,\n",
        "    'ytick.labelsize': 10,\n",
        "    'legend.fontsize': 10,\n",
        "    'figure.titlesize': 16\n",
        "})\n",
        "\n",
        "# Prepare data for visualizations\n",
        "test_dates = nhits_test_raw['ds'].values\n",
        "horizons_available = sorted([h for h in HORIZONS if h in m_nh_static and h in m_pr_static])\n",
        "\n",
        "# Extract metrics arrays\n",
        "rmse_nhits = np.array([m_nh_static[h][0] for h in horizons_available])\n",
        "rmse_prophet = np.array([m_pr_static[h][0] for h in horizons_available])\n",
        "rmse_baseline = np.array([m_base_static[h][0] for h in horizons_available])\n",
        "\n",
        "mae_nhits = np.array([m_nh_static[h][1] for h in horizons_available])\n",
        "mae_prophet = np.array([m_pr_static[h][1] for h in horizons_available])\n",
        "mae_baseline = np.array([m_base_static[h][1] for h in horizons_available])\n",
        "\n",
        "mape_nhits = np.array([m_nh_static[h][2] for h in horizons_available])\n",
        "mape_prophet = np.array([m_pr_static[h][2] for h in horizons_available])\n",
        "mape_baseline = np.array([m_base_static[h][2] for h in horizons_available])\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"GENERATING VISUALIZATIONS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# CHART 1: MULTI-HORIZON STATIC FORECASTS COMPARISON\n",
        "# ============================================================================\n",
        "viz_horizons = [7, 30, 90, 250]  # Key horizons for detailed analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 10))\n",
        "fig.suptitle('Static Forecast Performance Across Time Horizons', \n",
        "             fontsize=18, fontweight='bold', y=0.995)\n",
        "\n",
        "for idx, h in enumerate(viz_horizons):\n",
        "    if h in price_nhits_static_horizons and h in price_prophet_static_horizons:\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        dates_h = test_dates[:h]\n",
        "        actual_h = actual_prices[:h]\n",
        "        \n",
        "        # Plot with clear visual hierarchy\n",
        "        ax.plot(dates_h, actual_h, 'k-', lw=2.5, label='Actual', zorder=4, alpha=0.9)\n",
        "        ax.plot(dates_h, price_nhits_static_horizons[h], color='#2ecc71', \n",
        "                lw=2, label='N-HiTS', alpha=0.85, zorder=3)\n",
        "        ax.plot(dates_h, price_prophet_static_horizons[h], color='#3498db', \n",
        "                lw=2, label='Prophet', alpha=0.85, zorder=2)\n",
        "        ax.axhline(y=val_prices[-1], color='#e74c3c', linestyle='--', \n",
        "                   lw=1.5, label='Persistence', alpha=0.6, zorder=1)\n",
        "        \n",
        "        # Formatting\n",
        "        ax.set_title(f'{h}-Day Horizon | RMSE: N-HiTS ${m_nh_static[h][0]:.1f}, Prophet ${m_pr_static[h][0]:.1f}', \n",
        "                     fontweight='semibold', pad=8)\n",
        "        ax.set_ylabel('Price ($)', fontweight='semibold')\n",
        "        ax.legend(loc='best', framealpha=0.9, edgecolor='gray')\n",
        "        ax.grid(True, alpha=0.25, linestyle=':')\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=30, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('01_multi_horizon_comparison.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✅ Chart 1: Multi-horizon comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# CHART 2: ROLLING VS STATIC FORECASTS\n",
        "# ============================================================================\n",
        "fig = plt.figure(figsize=(18, 10))\n",
        "gs = GridSpec(2, 1, height_ratios=[1, 1], hspace=0.25)\n",
        "\n",
        "# Rolling forecasts (top panel)\n",
        "ax1 = fig.add_subplot(gs[0])\n",
        "ax1.plot(test_dates, actual_prices, 'k-', lw=2.5, label='Actual', alpha=0.9, zorder=4)\n",
        "ax1.plot(test_dates, price_nhits_rolling, color='#2ecc71', lw=2, \n",
        "         label=f'N-HiTS Rolling | RMSE: ${m_nh_rolling[0]:.1f}', alpha=0.85, zorder=3)\n",
        "ax1.plot(test_dates, price_prophet_rolling, color='#3498db', lw=2,\n",
        "         label=f'Prophet Rolling | RMSE: ${m_pr_rolling[0]:.1f}', alpha=0.85, zorder=2)\n",
        "ax1.plot(test_dates, price_base_rolling, color='#e74c3c', linestyle='--', lw=1.5,\n",
        "         label=f'Persistence | RMSE: ${m_base_rolling[0]:.1f}', alpha=0.6, zorder=1)\n",
        "\n",
        "ax1.set_title('Rolling 1-Step Forecasts (Daily Updates)', fontweight='bold', pad=10)\n",
        "ax1.set_ylabel('Price ($)', fontweight='semibold')\n",
        "ax1.legend(loc='upper left', framealpha=0.9, edgecolor='gray')\n",
        "ax1.grid(True, alpha=0.25, linestyle=':')\n",
        "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=30, ha='right')\n",
        "\n",
        "# Static forecasts (bottom panel)\n",
        "ax2 = fig.add_subplot(gs[1])\n",
        "max_h = max([h for h in HORIZONS if h <= len(actual_prices)])\n",
        "ax2.plot(test_dates[:max_h], actual_prices[:max_h], 'k-', lw=2.5, label='Actual', alpha=0.9, zorder=4)\n",
        "ax2.plot(test_dates[:max_h], price_nhits_static_horizons[max_h], color='#2ecc71', lw=2,\n",
        "         label=f'N-HiTS Static ({max_h}d) | RMSE: ${m_nh_static[max_h][0]:.1f}', alpha=0.85, zorder=3)\n",
        "ax2.plot(test_dates[:max_h], price_prophet_static_horizons[max_h], color='#3498db', lw=2,\n",
        "         label=f'Prophet Static ({max_h}d) | RMSE: ${m_pr_static[max_h][0]:.1f}', alpha=0.85, zorder=2)\n",
        "ax2.axhline(y=val_prices[-1], color='#e74c3c', linestyle='--', lw=1.5,\n",
        "            label=f'Persistence | RMSE: ${m_base_static[max_h][0]:.1f}', alpha=0.6, zorder=1)\n",
        "\n",
        "ax2.set_title(f'Static {max_h}-Day Forecast (Single Prediction)', fontweight='bold', pad=10)\n",
        "ax2.set_ylabel('Price ($)', fontweight='semibold')\n",
        "ax2.set_xlabel('Date', fontweight='semibold')\n",
        "ax2.legend(loc='upper left', framealpha=0.9, edgecolor='gray')\n",
        "ax2.grid(True, alpha=0.25, linestyle=':')\n",
        "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=30, ha='right')\n",
        "\n",
        "fig.suptitle('Forecast Mode Comparison: Rolling vs Static', fontsize=18, fontweight='bold', y=0.995)\n",
        "plt.savefig('02_rolling_vs_static.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✅ Chart 2: Rolling vs static comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# CHART 3: PERFORMANCE DEGRADATION ANALYSIS\n",
        "# ============================================================================\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Forecast Accuracy Degradation by Horizon', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics = [\n",
        "    (rmse_nhits, rmse_prophet, rmse_baseline, 'RMSE ($)', 'RMSE'),\n",
        "    (mae_nhits, mae_prophet, mae_baseline, 'MAE ($)', 'MAE'),\n",
        "    (mape_nhits, mape_prophet, mape_baseline, 'MAPE (%)', 'MAPE')\n",
        "]\n",
        "\n",
        "for ax, (m_nh, m_pr, m_base, ylabel, title) in zip(axes, metrics):\n",
        "    ax.plot(horizons_available, m_nh, 'o-', color='#2ecc71', lw=2.5, \n",
        "            markersize=8, label='N-HiTS', markeredgewidth=1.5, markeredgecolor='white')\n",
        "    ax.plot(horizons_available, m_pr, 's-', color='#3498db', lw=2.5,\n",
        "            markersize=8, label='Prophet', markeredgewidth=1.5, markeredgecolor='white')\n",
        "    ax.plot(horizons_available, m_base, '^--', color='#e74c3c', lw=2,\n",
        "            markersize=7, label='Baseline', alpha=0.7, markeredgewidth=1.5, markeredgecolor='white')\n",
        "    \n",
        "    ax.set_xlabel('Forecast Horizon (days)', fontweight='semibold')\n",
        "    ax.set_ylabel(ylabel, fontweight='semibold')\n",
        "    ax.set_title(f'{title} Degradation', fontweight='bold')\n",
        "    ax.legend(framealpha=0.9, edgecolor='gray')\n",
        "    ax.grid(True, alpha=0.25, linestyle=':')\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xticks(horizons_available)\n",
        "    ax.set_xticklabels([str(h) for h in horizons_available])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('03_performance_degradation.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✅ Chart 3: Performance degradation saved\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# CHART 4: ERROR DISTRIBUTION ANALYSIS\n",
        "# ============================================================================\n",
        "error_horizons = [7, 30, 90, 250]\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "fig.suptitle('Forecast Error Distribution by Horizon', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, h in enumerate(error_horizons):\n",
        "    if h in price_nhits_static_horizons and h in price_prophet_static_horizons:\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        \n",
        "        actual_h = actual_prices[:h]\n",
        "        errors = {\n",
        "            'N-HiTS': price_nhits_static_horizons[h] - actual_h,\n",
        "            'Prophet': price_prophet_static_horizons[h] - actual_h,\n",
        "            'Baseline': price_base_static[:h] - actual_h\n",
        "        }\n",
        "        \n",
        "        colors = {'N-HiTS': '#2ecc71', 'Prophet': '#3498db', 'Baseline': '#e74c3c'}\n",
        "        \n",
        "        for model, error in errors.items():\n",
        "            ax.hist(error, bins=25, alpha=0.5, label=model, \n",
        "                   color=colors[model], edgecolor=colors[model], linewidth=1.5)\n",
        "        \n",
        "        ax.axvline(x=0, color='black', linestyle='--', linewidth=1.5, alpha=0.5)\n",
        "        ax.set_title(f'{h}-Day Horizon', fontweight='bold')\n",
        "        ax.set_xlabel('Prediction Error ($)', fontweight='semibold')\n",
        "        ax.set_ylabel('Frequency', fontweight='semibold')\n",
        "        ax.legend(framealpha=0.9, edgecolor='gray')\n",
        "        ax.grid(True, alpha=0.25, linestyle=':', axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('04_error_distribution.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✅ Chart 4: Error distribution saved\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# CHART 5: CUMULATIVE ERROR ACCUMULATION\n",
        "# ============================================================================\n",
        "cum_horizons = [7, 30, 90, 250]\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "fig.suptitle('Cumulative Error Accumulation Over Time', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, h in enumerate(cum_horizons):\n",
        "    if h in price_nhits_static_horizons and h in price_prophet_static_horizons:\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        \n",
        "        actual_h = actual_prices[:h]\n",
        "        cum_errors = {\n",
        "            'N-HiTS': np.cumsum(np.abs(price_nhits_static_horizons[h] - actual_h)),\n",
        "            'Prophet': np.cumsum(np.abs(price_prophet_static_horizons[h] - actual_h)),\n",
        "            'Baseline': np.cumsum(np.abs(price_base_static[:h] - actual_h))\n",
        "        }\n",
        "        \n",
        "        days = np.arange(1, h + 1)\n",
        "        ax.plot(days, cum_errors['N-HiTS'], color='#2ecc71', lw=2.5, label='N-HiTS', alpha=0.85)\n",
        "        ax.plot(days, cum_errors['Prophet'], color='#3498db', lw=2.5, label='Prophet', alpha=0.85)\n",
        "        ax.plot(days, cum_errors['Baseline'], color='#e74c3c', linestyle='--', lw=2, label='Baseline', alpha=0.7)\n",
        "        \n",
        "        ax.set_title(f'{h}-Day Horizon', fontweight='bold')\n",
        "        ax.set_xlabel('Days Since Forecast', fontweight='semibold')\n",
        "        ax.set_ylabel('Cumulative Absolute Error ($)', fontweight='semibold')\n",
        "        ax.legend(loc='upper left', framealpha=0.9, edgecolor='gray')\n",
        "        ax.grid(True, alpha=0.25, linestyle=':')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('05_cumulative_error.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✅ Chart 5: Cumulative error saved\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# CHART 6: PERFORMANCE HEATMAP\n",
        "# ============================================================================\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "\n",
        "models = ['N-HiTS', 'Prophet', 'Baseline']\n",
        "rmse_matrix = np.array([\n",
        "    [m_nh_static[h][0] for h in horizons_available],\n",
        "    [m_pr_static[h][0] for h in horizons_available],\n",
        "    [m_base_static[h][0] for h in horizons_available]\n",
        "])\n",
        "\n",
        "im = ax.imshow(rmse_matrix, cmap='RdYlGn_r', aspect='auto', vmin=rmse_matrix.min(), vmax=rmse_matrix.max())\n",
        "\n",
        "ax.set_xticks(np.arange(len(horizons_available)))\n",
        "ax.set_yticks(np.arange(len(models)))\n",
        "ax.set_xticklabels([f'{h}d' for h in horizons_available])\n",
        "ax.set_yticklabels(models)\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "for i in range(len(models)):\n",
        "    for j in range(len(horizons_available)):\n",
        "        ax.text(j, i, f'${rmse_matrix[i, j]:.1f}', ha=\"center\", va=\"center\", \n",
        "               color=\"black\", fontsize=10, fontweight='bold')\n",
        "\n",
        "ax.set_title('RMSE Performance Heatmap', fontsize=14, fontweight='bold', pad=12)\n",
        "ax.set_xlabel('Forecast Horizon', fontweight='semibold')\n",
        "ax.set_ylabel('Model', fontweight='semibold')\n",
        "\n",
        "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "cbar.set_label('RMSE ($)', fontweight='semibold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('06_rmse_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✅ Chart 6: RMSE heatmap saved\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# CHART 7: COMPARATIVE BAR CHARTS\n",
        "# ============================================================================\n",
        "comp_horizon = 90 if 90 in m_nh_static else horizons_available[len(horizons_available)//2]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "fig.suptitle(f'Model Performance Comparison ({comp_horizon}-Day Horizon)', \n",
        "             fontsize=16, fontweight='bold')\n",
        "\n",
        "x_pos = np.arange(3)\n",
        "model_labels = ['N-HiTS', 'Prophet', 'Baseline']\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "\n",
        "metrics_data = [\n",
        "    ([m_nh_static[comp_horizon][0], m_pr_static[comp_horizon][0], m_base_static[comp_horizon][0]], \n",
        "     'RMSE ($)', '${:.1f}'),\n",
        "    ([m_nh_static[comp_horizon][1], m_pr_static[comp_horizon][1], m_base_static[comp_horizon][1]], \n",
        "     'MAE ($)', '${:.1f}'),\n",
        "    ([m_nh_static[comp_horizon][2], m_pr_static[comp_horizon][2], m_base_static[comp_horizon][2]], \n",
        "     'MAPE (%)', '{:.2f}%')\n",
        "]\n",
        "\n",
        "for ax, (values, ylabel, fmt) in zip(axes, metrics_data):\n",
        "    bars = ax.bar(x_pos, values, color=colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
        "    \n",
        "    ax.set_ylabel(ylabel, fontweight='semibold')\n",
        "    ax.set_title(ylabel.split()[0], fontweight='bold')\n",
        "    ax.set_xticks(x_pos)\n",
        "    ax.set_xticklabels(model_labels)\n",
        "    ax.grid(True, alpha=0.25, axis='y', linestyle=':')\n",
        "    \n",
        "    for bar, value in zip(bars, values):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height * 1.01,\n",
        "               fmt.format(value), ha='center', va='bottom', \n",
        "               fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('07_model_comparison_bars.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✅ Chart 7: Model comparison bars saved\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2affdd11",
      "metadata": {},
      "source": [
        "# Results & Discussion\n",
        "\n",
        "## Performance Overview\n",
        "\n",
        "The evaluation reveals distinct performance characteristics across forecast horizons and prediction modes. N-HiTS demonstrates superiority at short horizons (7-60 days), Prophet dominates long-term forecasts (90-250 days), while the naive persistence baseline unexpectedly outperforms both models in rolling 1-step predictions.\n",
        "\n",
        "---\n",
        "\n",
        "## Rolling Forecast Results\n",
        "\n",
        "| Model | RMSE ($) | MAE ($) | MAPE (%) |\n",
        "|-------|----------|---------|----------|\n",
        "| Persistence (Baseline) | 4.14 | 3.08 | 1.11 |\n",
        "| Prophet | 5.41 | 4.05 | 1.44 |\n",
        "| N-HiTS | 9.43 | 7.40 | 2.57 |\n",
        "\n",
        "The persistence baseline achieves lowest error across all metrics, validating the random walk hypothesis at daily granularity. Adobe's 2019 daily volatility averaged 1-2%, creating conditions where today's price serves as the optimal predictor for tomorrow. Both sophisticated models introduce complexity that increases rather than reduces prediction error at this timescale, demonstrating that market efficiency at ultra-short horizons renders pattern-based and trend-based approaches ineffective.\n",
        "\n",
        "---\n",
        "\n",
        "## Static Forecast Results\n",
        "\n",
        "### Short-Horizon Performance (7-60 Days)\n",
        "\n",
        "**7-Day Horizon:**\n",
        "\n",
        "| Model | RMSE ($) | MAE ($) | MAPE (%) |\n",
        "|-------|----------|---------|----------|\n",
        "| N-HiTS | 6.77 | 5.48 | 2.41 |\n",
        "| Persistence | 7.39 | 6.06 | 2.64 |\n",
        "| Prophet | 10.44 | 8.24 | 3.58 |\n",
        "\n",
        "**30-Day Horizon:**\n",
        "\n",
        "| Model | RMSE ($) | MAE ($) | MAPE (%) |\n",
        "|-------|----------|---------|----------|\n",
        "| N-HiTS | 13.49 | 12.17 | 4.92 |\n",
        "| Prophet | 13.83 | 11.55 | 4.68 |\n",
        "| Persistence | 20.22 | 17.88 | 7.20 |\n",
        "\n",
        "**60-Day Horizon:**\n",
        "\n",
        "| Model | RMSE ($) | MAE ($) | MAPE (%) |\n",
        "|-------|----------|---------|----------|\n",
        "| N-HiTS | 17.05 | 15.94 | 6.24 |\n",
        "| Prophet | 17.33 | 14.46 | 5.67 |\n",
        "| Persistence | 28.17 | 26.03 | 10.16 |\n",
        "\n",
        "N-HiTS achieves 8-35% lower RMSE than Prophet at horizons up to 60 days, directly corresponding to its optimization configuration (`output_chunk_length=60`). The hierarchical architecture captures multi-scale patterns—weekly cycles, monthly momentum, and short-term volatility clustering—that remain predictive at these timescales. Performance peaks at the 60-day training horizon with 1.6% advantage over Prophet, demonstrating that both models reached comparable optimization effectiveness for their target prediction length.\n",
        "\n",
        "### Medium-Horizon Transition (90 Days)\n",
        "\n",
        "| Model | RMSE ($) | MAE ($) | MAPE (%) |\n",
        "|-------|----------|---------|----------|\n",
        "| Prophet | 16.47 | 13.65 | 5.23 |\n",
        "| N-HiTS | 22.69 | 21.10 | 7.97 |\n",
        "| Persistence | 36.60 | 33.66 | 12.69 |\n",
        "\n",
        "Prophet overtakes N-HiTS by 27% at 90 days, marking the critical crossover point. The performance reversal reflects pattern extrapolation failure in N-HiTS rather than error compounding. Since N-HiTS generates direct multi-step predictions (non-autoregressive), errors do not accumulate sequentially. Instead, degradation stems from three factors:\n",
        "\n",
        "**Pattern Extrapolation Beyond Training Horizon:** The model trained with `output_chunk_length=60` extrapolates when predicting 90+ days, analogous to statistical extrapolation beyond observed data ranges. Short-term patterns learned from training data—momentum persistence, volatility clustering, mean reversion cycles—remain valid for 30-60 days but break down over longer periods.\n",
        "\n",
        "**Regime-Specific Overfitting:** Neural networks embed training period characteristics (2014-2017 volatility levels, drift rates, correlation structures) into learned weights. When test period market dynamics differ, learned patterns fail to generalize without structural constraints to anchor predictions. This also states N-HITS might perform better trained on the whole horizon and tested on volatile (post-COVID) periods.\n",
        "\n",
        "**Architectural Design Limitations:** Unlike Prophet's explicit trend component providing long-term stability, N-HiTS lacks built-in mechanisms ensuring sensible extended forecasts. The hierarchical interpolation architecture excels on pattern-rich datasets (electricity demand, traffic) but struggles with low-signal financial time series at long horizons.\n",
        "\n",
        "Prophet maintains stable performance through structural decomposition (`Price = Trend + Seasonality + Holidays + Noise`). The piecewise linear trend provides consistent direction, while yearly and quarterly seasonal components remain valid predictors at extended horizons. Conservative extrapolation prevents wild predictions that plague unconstrained neural networks.\n",
        "\n",
        "### Long-Horizon Performance (180-250 Days)\n",
        "\n",
        "**180-Day Horizon:**\n",
        "\n",
        "| Model | RMSE ($) | MAE ($) | MAPE (%) |\n",
        "|-------|----------|---------|----------|\n",
        "| Prophet | 16.92 | 14.47 | 5.24 |\n",
        "| N-HiTS | 34.47 | 31.01 | 10.99 |\n",
        "| Persistence | 51.86 | 47.98 | 17.06 |\n",
        "\n",
        "**250-Day Horizon:**\n",
        "\n",
        "| Model | RMSE ($) | MAE ($) | MAPE (%) |\n",
        "|-------|----------|---------|----------|\n",
        "| Prophet | 20.99 | 17.22 | 6.20 |\n",
        "| N-HiTS | 38.61 | 34.53 | 12.00 |\n",
        "| Persistence | 56.84 | 52.78 | 18.45 |\n",
        "\n",
        "Prophet achieves 46-51% lower RMSE than N-HiTS at horizons beyond 180 days. The advantage stems from structural components persisting at long horizons—annual seasonality, quarterly earnings cycles, and linear trend—while short-term technical patterns captured by N-HiTS lose predictive power. Prophet's decomposition separates persistent signal from transient noise, focusing long-term predictions on components that generalize across market regimes.\n",
        "\n",
        "---\n",
        "\n",
        "## Performance Degradation Analysis\n",
        "\n",
        "| Horizon | N-HiTS RMSE ($) | Prophet RMSE ($) | N-HiTS Δ | Prophet Δ |\n",
        "|---------|-----------------|------------------|----------|-----------|\n",
        "| 7 days  | 6.77 | 10.44 | — | — |\n",
        "| 60 days | 17.05 | 17.33 | +152% | +66% |\n",
        "| 90 days | 22.69 | 16.47 | +235% | +58% |\n",
        "| 180 days | 34.47 | 16.92 | +409% | +62% |\n",
        "| 250 days | 38.61 | 20.99 | +470% | +101% |\n",
        "\n",
        "N-HiTS exhibits exponential degradation beyond the 60-day training horizon (5.7× increase from 7 to 250 days), while Prophet shows linear degradation with a stable plateau (2.0× increase over the same range). The contrasting profiles reflect pattern extrapolation failure versus robust structural modeling. N-HiTS transitions from interpolation (within training range) to unreliable extrapolation at 90+ days, while Prophet's simple additive structure maintains consistent behavior across all horizons.\n",
        "\n",
        "---\n",
        "\n",
        "## Data Limitations and Generalization\n",
        "\n",
        "The 4-year training period (2014-2017, ~1,008 trading days) captured post-crisis stable growth with moderate volatility (VIX 14-16) but limited exposure to diverse market regimes—no high-volatility crises, sharp corrections (>20%), or directional diversity beyond upward trends. N-HiTS requires varied training examples for effective generalization; the restricted regime exposure limits long-horizon performance.\n",
        "\n",
        "Training on the full 1986-2018 dataset would provide 8× more examples and diverse market conditions (1987 crash, 2000 dot-com bubble, 2008 financial crisis, various volatility regimes). Conservative estimates suggest 15-25% improvement at 180-250 day horizons with expanded training data, likely yielding a different result.\n",
        "\n",
        "The decision to use identical 2014-2017 training periods for both models ensures fair comparison by isolating architectural differences from data quantity effects. Training N-HiTS on 30+ years while restricting Prophet to 4 years would confound model architecture performance with data availability advantages.\n",
        "\n",
        "---\n",
        "\n",
        "## Model Selection Guidelines\n",
        "\n",
        "| Forecast Horizon | Recommended Model | Performance Advantage |\n",
        "|------------------|-------------------|----------------------|\n",
        "| 1 day (rolling) | Persistence | Outperforms both models by 23-56% |\n",
        "| 7-60 days | N-HiTS | 2-35% better than Prophet |\n",
        "| 90-250 days | Prophet | 27-51% better than N-HiTS |\n",
        "\n",
        "This approach leverages each model's strengths while avoiding weaknesses, providing optimal accuracy across practical forecast horizons.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The evaluation reveals that model performance is fundamentally tied to optimization configuration, not only inherent architectural superiority. N-HiTS achieves optimal performance upto the 60-day horizon for which it was trained (`output_chunk_length=60`), with competitive results extending from 30-60 days. Beyond this trained range, performance deteriorates rapidly—Prophet outperforms N-HiTS by substantial margins at longer horizons (90-250 days).\n",
        "\n",
        "Prophet demonstrates consistent performance across all forecast horizons due to its structural decomposition approach. The explicit modeling of trend and seasonal components provides stable extrapolation regardless of prediction length, making it the more robust general-purpose forecasting tool. Prophet's trend-based architecture naturally extends to any timeframe without requiring horizon-specific training.\n",
        "\n",
        "**Key Finding:** N-HiTS functions as a specialist optimized for its training horizon, while Prophet operates as a generalist maintaining reliability across diverse forecast lengths. The neural network's pattern recognition advantages materialize only within a narrow window around its training configuration. Outside this range, the statistical model's structural stability proves superior.\n",
        "\n",
        "For stock forecasting applications, this implies that N-HiTS requires careful horizon-specific tuning to match operational needs, whereas Prophet provides comparatively consistent performance without such constraints. The persistence baseline's dominance at 1-day rolling forecasts validates market efficiency at ultra-short timescales, indicating that model sophistication should align with underlying predictability rather than defaulting to architectural complexity.\n",
        "\n",
        "The results establish that N-HITS serves as the superior model given the short-term stock performance prediction relevance in real world and dominance over the horizon it optimizes for. However, on short training periods and long horizon static forecasting, Prophet dominates."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
